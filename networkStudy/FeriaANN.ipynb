{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "from os import listdir\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Dropout, MaxPooling1D, GlobalAveragePooling1D, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l1,l2\n",
    "import keras.backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "import regex as re\n",
    "\n",
    "dName = re.compile('_[A-Za-z0-9]*.mat')\n",
    "\n",
    "tWindow = 25\n",
    "\n",
    "def prepareData(data, tags):\n",
    "    currFrame = 0\n",
    "    retData = []\n",
    "    retTags = []\n",
    "    for index, row in tags.iterrows():\n",
    "        start = (int(int(row[0])*25))\n",
    "        stop = (int(int(row[1])*25))\n",
    "        if(start != stop):\n",
    "            retData.append(data[start:stop])\n",
    "            retTags.append(1 if row[2] not in [\"(nothing)\", \"multiple_actions\"] else 0)\n",
    "            currFrame = stop - 1\n",
    "        else:\n",
    "            if(start == currFrame):\n",
    "                retTags[-1] = int(retTags[-1] or (1 if row[2] not in [\"(nothing)\", \"multiple_actions\"] else 0))\n",
    "            else:\n",
    "                retData.append(np.array([data[start]]))\n",
    "                retTags.append(1 if row[2] not in [\"(nothing)\", \"multiple_actions\"] else 0)\n",
    "                currFrame = stop\n",
    "    return np.array(retData), np.array(retTags)\n",
    "\n",
    "def flattenData(data, tags):\n",
    "    residue = []\n",
    "    retData = []\n",
    "    retTags = []\n",
    "    index = 0\n",
    "    lastTag = 0\n",
    "    for item in data:\n",
    "        if(len(residue) > 0):\n",
    "            item = np.concatenate((residue, item), axis = 0)\n",
    "        if(len(item) >= tWindow):\n",
    "            i = 0\n",
    "            while(len(item) > i+tWindow):\n",
    "                retData.append(item[i:i+tWindow])\n",
    "                retTags.append(1 if ((len(residue) > 0 and lastTag == 1) or tags[index] == 1) else 0)\n",
    "                i += tWindow\n",
    "            if(len(item)%tWindow != 0):\n",
    "                residue = item[i:len(item)]\n",
    "            lastTag = tags[index]\n",
    "        else:\n",
    "            residue = item\n",
    "            lastTag = 1 if (lastTag == 1 or tags[index] == 1) else 0\n",
    "        index += 1\n",
    "    if(len(residue) > 0):\n",
    "        retData.append(np.concatenate((residue, np.zeros((tWindow-len(residue), 22))), axis = 0))\n",
    "        retTags.append(1 if ((len(residue) > 0 and lastTag == 1) or tags[index-1] == 1) else 0)\n",
    "    return np.array(retData), np.array(retTags)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataPath = \"./Datasets/VSD_2014_December_official_release/Hollywood-dev/features/\"\n",
    "annotationsPath = \"./Datasets/VSD_2014_December_official_release/Hollywood-dev/annotations/\"\n",
    "\n",
    "data_names = listdir(annotationsPath)\n",
    "\n",
    "uDataNames = set()\n",
    "\n",
    "for fname in data_names:\n",
    "    if (\"screams\" in fname):\n",
    "        uDataNames.add(fname.replace('_screams.txt', ''))\n",
    "        \n",
    "uDataNames = list(uDataNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 20, 64)            8512      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            49408     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 6, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 2, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3000)              1539000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3001      \n",
      "=================================================================\n",
      "Total params: 2,060,465\n",
      "Trainable params: 2,059,953\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 6, activation='relu', input_shape=(tWindow, 22), kernel_initializer='uniform',kernel_regularizer=l2(0.01)))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(512, 2, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3000, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReservoirDogs\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4568 samples, validate on 1142 samples\n",
      "Epoch 1/25\n",
      "4568/4568 [==============================] - 8s 2ms/step - loss: 0.4380 - acc: 0.8581 - val_loss: 0.6315 - val_acc: 0.7802\n",
      "Epoch 2/25\n",
      "4568/4568 [==============================] - 3s 618us/step - loss: 0.4054 - acc: 0.8608 - val_loss: 0.5812 - val_acc: 0.7802\n",
      "Epoch 3/25\n",
      "4568/4568 [==============================] - 3s 620us/step - loss: 0.4032 - acc: 0.8608 - val_loss: 0.6389 - val_acc: 0.7802\n",
      "Epoch 4/25\n",
      "4568/4568 [==============================] - 3s 612us/step - loss: 0.4018 - acc: 0.8608 - val_loss: 0.6799 - val_acc: 0.7802\n",
      "Epoch 5/25\n",
      "4568/4568 [==============================] - 3s 617us/step - loss: 0.4012 - acc: 0.8608 - val_loss: 0.5839 - val_acc: 0.7802\n",
      "Epoch 6/25\n",
      "4568/4568 [==============================] - 3s 618us/step - loss: 0.3996 - acc: 0.8608 - val_loss: 0.6065 - val_acc: 0.7802\n",
      "Epoch 7/25\n",
      "4568/4568 [==============================] - 3s 623us/step - loss: 0.3998 - acc: 0.8608 - val_loss: 0.5464 - val_acc: 0.7802\n",
      "Epoch 8/25\n",
      "4568/4568 [==============================] - 3s 639us/step - loss: 0.3987 - acc: 0.8606 - val_loss: 0.5647 - val_acc: 0.7802\n",
      "Epoch 9/25\n",
      "4568/4568 [==============================] - 3s 634us/step - loss: 0.3976 - acc: 0.8608 - val_loss: 0.5835 - val_acc: 0.7802\n",
      "Epoch 10/25\n",
      "4568/4568 [==============================] - ETA: 0s - loss: 0.3951 - acc: 0.861 - 3s 626us/step - loss: 0.3959 - acc: 0.8612 - val_loss: 0.5364 - val_acc: 0.7802\n",
      "Epoch 11/25\n",
      "4568/4568 [==============================] - 3s 627us/step - loss: 0.3961 - acc: 0.8619 - val_loss: 0.5517 - val_acc: 0.7802\n",
      "Epoch 12/25\n",
      "4568/4568 [==============================] - 3s 629us/step - loss: 0.3955 - acc: 0.8601 - val_loss: 0.5412 - val_acc: 0.7802\n",
      "Epoch 13/25\n",
      "4568/4568 [==============================] - 3s 626us/step - loss: 0.3929 - acc: 0.8623 - val_loss: 0.5528 - val_acc: 0.7802\n",
      "Epoch 14/25\n",
      "4568/4568 [==============================] - 3s 630us/step - loss: 0.3924 - acc: 0.8610 - val_loss: 0.5768 - val_acc: 0.7767\n",
      "Epoch 15/25\n",
      "4568/4568 [==============================] - 3s 629us/step - loss: 0.3910 - acc: 0.8636 - val_loss: 0.5380 - val_acc: 0.7811\n",
      "Epoch 16/25\n",
      "4568/4568 [==============================] - 3s 626us/step - loss: 0.3911 - acc: 0.8641 - val_loss: 0.5540 - val_acc: 0.7811\n",
      "Epoch 17/25\n",
      "4568/4568 [==============================] - 3s 627us/step - loss: 0.3895 - acc: 0.8632 - val_loss: 0.5615 - val_acc: 0.7811\n",
      "Epoch 18/25\n",
      "4568/4568 [==============================] - 3s 631us/step - loss: 0.3895 - acc: 0.8643 - val_loss: 0.5622 - val_acc: 0.7828\n",
      "Epoch 19/25\n",
      "4568/4568 [==============================] - 3s 627us/step - loss: 0.3875 - acc: 0.8651 - val_loss: 0.5395 - val_acc: 0.7802\n",
      "Epoch 20/25\n",
      "4568/4568 [==============================] - 3s 621us/step - loss: 0.3908 - acc: 0.8643 - val_loss: 0.5738 - val_acc: 0.7820\n",
      "Epoch 21/25\n",
      "4568/4568 [==============================] - 3s 624us/step - loss: 0.3863 - acc: 0.8645 - val_loss: 0.5600 - val_acc: 0.7820\n",
      "Epoch 22/25\n",
      "4568/4568 [==============================] - 3s 628us/step - loss: 0.3890 - acc: 0.8634 - val_loss: 0.5476 - val_acc: 0.7820\n",
      "Epoch 23/25\n",
      "4568/4568 [==============================] - 3s 625us/step - loss: 0.3894 - acc: 0.8641 - val_loss: 0.6252 - val_acc: 0.7469\n",
      "Epoch 24/25\n",
      "4568/4568 [==============================] - 3s 633us/step - loss: 0.3852 - acc: 0.8658 - val_loss: 0.5706 - val_acc: 0.7828\n",
      "Epoch 25/25\n",
      "4568/4568 [==============================] - 3s 630us/step - loss: 0.3839 - acc: 0.8662 - val_loss: 0.6945 - val_acc: 0.7697\n",
      "Training advancement:  0 %\n",
      "Eragon\n",
      "Train on 4780 samples, validate on 1196 samples\n",
      "Epoch 1/60\n",
      "4780/4780 [==============================] - 3s 637us/step - loss: 0.5740 - acc: 0.7435 - val_loss: 1.8304 - val_acc: 0.4707\n",
      "Epoch 2/60\n",
      "4780/4780 [==============================] - 3s 631us/step - loss: 0.5456 - acc: 0.7567 - val_loss: 1.4151 - val_acc: 0.4707\n",
      "Epoch 3/60\n",
      "4780/4780 [==============================] - 3s 632us/step - loss: 0.5408 - acc: 0.7579 - val_loss: 0.8491 - val_acc: 0.4590\n",
      "Epoch 4/60\n",
      "4780/4780 [==============================] - 3s 633us/step - loss: 0.5420 - acc: 0.7582 - val_loss: 0.9224 - val_acc: 0.4707\n",
      "Epoch 5/60\n",
      "4780/4780 [==============================] - 3s 632us/step - loss: 0.5349 - acc: 0.7575 - val_loss: 0.7762 - val_acc: 0.5485\n",
      "Epoch 6/60\n",
      "4780/4780 [==============================] - 3s 629us/step - loss: 0.5355 - acc: 0.7579 - val_loss: 0.9185 - val_acc: 0.4707\n",
      "Epoch 7/60\n",
      "4780/4780 [==============================] - 3s 631us/step - loss: 0.5375 - acc: 0.7586 - val_loss: 0.9493 - val_acc: 0.4916\n",
      "Epoch 8/60\n",
      "4780/4780 [==============================] - 3s 628us/step - loss: 0.5337 - acc: 0.7575 - val_loss: 0.9428 - val_acc: 0.4758\n",
      "Epoch 9/60\n",
      "4780/4780 [==============================] - 3s 628us/step - loss: 0.5339 - acc: 0.7596 - val_loss: 0.7853 - val_acc: 0.5084\n",
      "Epoch 10/60\n",
      "4780/4780 [==============================] - 3s 633us/step - loss: 0.5296 - acc: 0.7592 - val_loss: 0.9089 - val_acc: 0.5309\n",
      "Epoch 11/60\n",
      "4780/4780 [==============================] - 3s 629us/step - loss: 0.5319 - acc: 0.7584 - val_loss: 0.7374 - val_acc: 0.5803\n",
      "Epoch 12/60\n",
      "4780/4780 [==============================] - 3s 628us/step - loss: 0.5299 - acc: 0.7613 - val_loss: 0.7418 - val_acc: 0.5903\n",
      "Epoch 13/60\n",
      "4780/4780 [==============================] - 3s 627us/step - loss: 0.5259 - acc: 0.7636 - val_loss: 0.8100 - val_acc: 0.5836\n",
      "Epoch 14/60\n",
      "4780/4780 [==============================] - 3s 630us/step - loss: 0.5263 - acc: 0.7663 - val_loss: 0.8081 - val_acc: 0.5602 loss: 0.525\n",
      "Epoch 15/60\n",
      "4780/4780 [==============================] - 3s 631us/step - loss: 0.5243 - acc: 0.7644 - val_loss: 0.8502 - val_acc: 0.5401\n",
      "Epoch 16/60\n",
      "4780/4780 [==============================] - 3s 639us/step - loss: 0.5247 - acc: 0.7642 - val_loss: 0.8284 - val_acc: 0.5569\n",
      "Epoch 17/60\n",
      "4780/4780 [==============================] - 3s 632us/step - loss: 0.5201 - acc: 0.7711 - val_loss: 1.0204 - val_acc: 0.5008\n",
      "Epoch 18/60\n",
      "4780/4780 [==============================] - 3s 625us/step - loss: 0.5213 - acc: 0.7684 - val_loss: 0.8341 - val_acc: 0.5803\n",
      "Epoch 19/60\n",
      "4780/4780 [==============================] - 3s 628us/step - loss: 0.5220 - acc: 0.7674 - val_loss: 0.9287 - val_acc: 0.5527\n",
      "Epoch 20/60\n",
      "4780/4780 [==============================] - 3s 631us/step - loss: 0.5198 - acc: 0.7676 - val_loss: 0.8257 - val_acc: 0.4908\n",
      "Epoch 21/60\n",
      "4780/4780 [==============================] - 3s 632us/step - loss: 0.5213 - acc: 0.7663 - val_loss: 0.8244 - val_acc: 0.5192\n",
      "Epoch 22/60\n",
      "4780/4780 [==============================] - 3s 635us/step - loss: 0.5171 - acc: 0.7711 - val_loss: 0.8257 - val_acc: 0.5853\n",
      "Epoch 23/60\n",
      "4780/4780 [==============================] - 3s 629us/step - loss: 0.5172 - acc: 0.7722 - val_loss: 0.8722 - val_acc: 0.5351\n",
      "Epoch 24/60\n",
      "4780/4780 [==============================] - 3s 626us/step - loss: 0.5166 - acc: 0.7707 - val_loss: 0.7491 - val_acc: 0.6137\n",
      "Epoch 25/60\n",
      "4780/4780 [==============================] - 3s 628us/step - loss: 0.5131 - acc: 0.7705 - val_loss: 0.8678 - val_acc: 0.5870\n",
      "Epoch 26/60\n",
      "4780/4780 [==============================] - 3s 633us/step - loss: 0.5140 - acc: 0.7736 - val_loss: 0.7452 - val_acc: 0.6012\n",
      "Epoch 27/60\n",
      "4780/4780 [==============================] - 3s 661us/step - loss: 0.5106 - acc: 0.7688 - val_loss: 0.8499 - val_acc: 0.5552\n",
      "Epoch 28/60\n",
      "4780/4780 [==============================] - 3s 619us/step - loss: 0.5100 - acc: 0.7789 - val_loss: 0.7600 - val_acc: 0.5861\n",
      "Epoch 29/60\n",
      "4780/4780 [==============================] - 3s 618us/step - loss: 0.5061 - acc: 0.7762 - val_loss: 1.1484 - val_acc: 0.5276\n",
      "Epoch 30/60\n",
      "4780/4780 [==============================] - 3s 628us/step - loss: 0.5062 - acc: 0.7751 - val_loss: 0.8184 - val_acc: 0.5753\n",
      "Epoch 31/60\n",
      "4780/4780 [==============================] - 3s 617us/step - loss: 0.5050 - acc: 0.7764 - val_loss: 0.7242 - val_acc: 0.5435\n",
      "Epoch 32/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4780/4780 [==============================] - 3s 625us/step - loss: 0.5022 - acc: 0.7818 - val_loss: 1.6183 - val_acc: 0.4916\n",
      "Epoch 33/60\n",
      "4780/4780 [==============================] - 3s 621us/step - loss: 0.5009 - acc: 0.7818 - val_loss: 0.7612 - val_acc: 0.5326\n",
      "Epoch 34/60\n",
      "4780/4780 [==============================] - 3s 619us/step - loss: 0.4972 - acc: 0.7862 - val_loss: 0.8063 - val_acc: 0.5644\n",
      "Epoch 35/60\n",
      "4780/4780 [==============================] - 3s 619us/step - loss: 0.4930 - acc: 0.7885 - val_loss: 0.9624 - val_acc: 0.5209\n",
      "Epoch 36/60\n",
      "4780/4780 [==============================] - 3s 626us/step - loss: 0.4959 - acc: 0.7847 - val_loss: 0.7766 - val_acc: 0.5510\n",
      "Epoch 37/60\n",
      "4780/4780 [==============================] - 3s 647us/step - loss: 0.4857 - acc: 0.7923 - val_loss: 0.7952 - val_acc: 0.5226\n",
      "Epoch 38/60\n",
      "4780/4780 [==============================] - 3s 629us/step - loss: 0.4814 - acc: 0.7954 - val_loss: 1.1469 - val_acc: 0.4875\n",
      "Epoch 39/60\n",
      "4780/4780 [==============================] - 3s 630us/step - loss: 0.4817 - acc: 0.7925 - val_loss: 0.7365 - val_acc: 0.6062\n",
      "Epoch 40/60\n",
      "4780/4780 [==============================] - 3s 639us/step - loss: 0.4709 - acc: 0.7990 - val_loss: 0.8616 - val_acc: 0.5477\n",
      "Epoch 41/60\n",
      "4780/4780 [==============================] - 3s 627us/step - loss: 0.4691 - acc: 0.8033 - val_loss: 0.7652 - val_acc: 0.5652\n",
      "Epoch 42/60\n",
      "4780/4780 [==============================] - 3s 625us/step - loss: 0.4633 - acc: 0.8115 - val_loss: 0.8693 - val_acc: 0.5159\n",
      "Epoch 43/60\n",
      "4780/4780 [==============================] - 3s 632us/step - loss: 0.4569 - acc: 0.8084 - val_loss: 0.7833 - val_acc: 0.5953\n",
      "Epoch 44/60\n",
      "4780/4780 [==============================] - 3s 630us/step - loss: 0.4543 - acc: 0.8159 - val_loss: 1.5444 - val_acc: 0.4941\n",
      "Epoch 45/60\n",
      "4780/4780 [==============================] - 3s 635us/step - loss: 0.4461 - acc: 0.8207 - val_loss: 0.9858 - val_acc: 0.5594\n",
      "Epoch 46/60\n",
      "4780/4780 [==============================] - 3s 630us/step - loss: 0.4367 - acc: 0.8224 - val_loss: 1.4050 - val_acc: 0.5134\n",
      "Epoch 47/60\n",
      "4780/4780 [==============================] - 3s 638us/step - loss: 0.4324 - acc: 0.8241 - val_loss: 1.1153 - val_acc: 0.5527\n",
      "Epoch 48/60\n",
      "4780/4780 [==============================] - 3s 631us/step - loss: 0.4228 - acc: 0.8351 - val_loss: 0.7966 - val_acc: 0.6129\n",
      "Epoch 49/60\n",
      "4780/4780 [==============================] - 3s 629us/step - loss: 0.4111 - acc: 0.8397 - val_loss: 0.9225 - val_acc: 0.4983\n",
      "Epoch 50/60\n",
      "4780/4780 [==============================] - 3s 630us/step - loss: 0.4016 - acc: 0.8435 - val_loss: 1.0945 - val_acc: 0.5117\n",
      "Epoch 51/60\n",
      "4780/4780 [==============================] - 3s 632us/step - loss: 0.3918 - acc: 0.8462 - val_loss: 1.2335 - val_acc: 0.5067\n",
      "Epoch 52/60\n",
      "4780/4780 [==============================] - 3s 625us/step - loss: 0.3788 - acc: 0.8575 - val_loss: 0.9373 - val_acc: 0.5769\n",
      "Epoch 53/60\n",
      "4780/4780 [==============================] - 3s 631us/step - loss: 0.3693 - acc: 0.8584 - val_loss: 1.4676 - val_acc: 0.5527\n",
      "Epoch 54/60\n",
      "4780/4780 [==============================] - 3s 630us/step - loss: 0.3586 - acc: 0.8669 - val_loss: 1.1942 - val_acc: 0.5585\n",
      "Epoch 55/60\n",
      "4780/4780 [==============================] - 3s 650us/step - loss: 0.3363 - acc: 0.8787 - val_loss: 1.1531 - val_acc: 0.5460\n",
      "Epoch 56/60\n",
      "4780/4780 [==============================] - 3s 634us/step - loss: 0.3305 - acc: 0.8743 - val_loss: 1.0726 - val_acc: 0.5251\n",
      "Epoch 57/60\n",
      "4780/4780 [==============================] - 3s 616us/step - loss: 0.3179 - acc: 0.8843 - val_loss: 1.0558 - val_acc: 0.5360\n",
      "Epoch 58/60\n",
      "4780/4780 [==============================] - 3s 625us/step - loss: 0.2956 - acc: 0.8962 - val_loss: 3.1445 - val_acc: 0.5343\n",
      "Epoch 59/60\n",
      "4780/4780 [==============================] - 3s 620us/step - loss: 0.2776 - acc: 0.9021 - val_loss: 1.5547 - val_acc: 0.5953\n",
      "Epoch 60/60\n",
      "4780/4780 [==============================] - 3s 624us/step - loss: 0.2601 - acc: 0.9079 - val_loss: 0.8564 - val_acc: 0.6020\n",
      "Training advancement:  0 %\n",
      "BillyElliot\n",
      "Train on 5076 samples, validate on 1270 samples\n",
      "Epoch 1/60\n",
      "5076/5076 [==============================] - 3s 634us/step - loss: 0.5982 - acc: 0.7459 - val_loss: 0.7875 - val_acc: 0.6890\n",
      "Epoch 2/60\n",
      "5076/5076 [==============================] - 3s 622us/step - loss: 0.5601 - acc: 0.7530 - val_loss: 0.6689 - val_acc: 0.6504\n",
      "Epoch 3/60\n",
      "5076/5076 [==============================] - 3s 614us/step - loss: 0.5467 - acc: 0.7547 - val_loss: 0.7855 - val_acc: 0.5260\n",
      "Epoch 4/60\n",
      "5076/5076 [==============================] - 3s 622us/step - loss: 0.5355 - acc: 0.7537 - val_loss: 2.7356 - val_acc: 0.3071\n",
      "Epoch 5/60\n",
      "5076/5076 [==============================] - 3s 615us/step - loss: 0.5238 - acc: 0.7618 - val_loss: 0.6414 - val_acc: 0.6685\n",
      "Epoch 6/60\n",
      "5076/5076 [==============================] - 3s 619us/step - loss: 0.5126 - acc: 0.7669 - val_loss: 0.6585 - val_acc: 0.6197\n",
      "Epoch 7/60\n",
      "5076/5076 [==============================] - 3s 620us/step - loss: 0.5006 - acc: 0.7752 - val_loss: 0.7274 - val_acc: 0.6205\n",
      "Epoch 8/60\n",
      "5076/5076 [==============================] - 3s 613us/step - loss: 0.4912 - acc: 0.7839 - val_loss: 0.6836 - val_acc: 0.6756\n",
      "Epoch 9/60\n",
      "5076/5076 [==============================] - 3s 615us/step - loss: 0.4796 - acc: 0.7882 - val_loss: 0.8197 - val_acc: 0.6063\n",
      "Epoch 10/60\n",
      "5076/5076 [==============================] - 3s 617us/step - loss: 0.4659 - acc: 0.8004 - val_loss: 1.4909 - val_acc: 0.5480\n",
      "Epoch 11/60\n",
      "5076/5076 [==============================] - 3s 614us/step - loss: 0.4569 - acc: 0.8036 - val_loss: 1.0562 - val_acc: 0.6787\n",
      "Epoch 12/60\n",
      "5076/5076 [==============================] - 3s 623us/step - loss: 0.4447 - acc: 0.8115 - val_loss: 1.1135 - val_acc: 0.6937\n",
      "Epoch 13/60\n",
      "5076/5076 [==============================] - 3s 620us/step - loss: 0.4313 - acc: 0.8170 - val_loss: 0.7047 - val_acc: 0.6898\n",
      "Epoch 14/60\n",
      "5076/5076 [==============================] - 3s 616us/step - loss: 0.4158 - acc: 0.8264 - val_loss: 0.9290 - val_acc: 0.6315\n",
      "Epoch 15/60\n",
      "5076/5076 [==============================] - 3s 620us/step - loss: 0.4026 - acc: 0.8316 - val_loss: 1.3784 - val_acc: 0.6913\n",
      "Epoch 16/60\n",
      "5076/5076 [==============================] - 3s 622us/step - loss: 0.3833 - acc: 0.8438 - val_loss: 1.1802 - val_acc: 0.6189\n",
      "Epoch 17/60\n",
      "5076/5076 [==============================] - 3s 629us/step - loss: 0.3789 - acc: 0.8475 - val_loss: 1.0261 - val_acc: 0.6630\n",
      "Epoch 18/60\n",
      "5076/5076 [==============================] - 3s 615us/step - loss: 0.3650 - acc: 0.8491 - val_loss: 0.9039 - val_acc: 0.6228\n",
      "Epoch 19/60\n",
      "5076/5076 [==============================] - 3s 632us/step - loss: 0.3456 - acc: 0.8599 - val_loss: 4.8625 - val_acc: 0.6913\n",
      "Epoch 20/60\n",
      "5076/5076 [==============================] - 3s 635us/step - loss: 0.3452 - acc: 0.8641 - val_loss: 4.4965 - val_acc: 0.6866\n",
      "Epoch 21/60\n",
      "5076/5076 [==============================] - 3s 630us/step - loss: 0.3291 - acc: 0.8729 - val_loss: 0.9347 - val_acc: 0.6323\n",
      "Epoch 22/60\n",
      "5076/5076 [==============================] - 3s 630us/step - loss: 0.3020 - acc: 0.8818 - val_loss: 1.2372 - val_acc: 0.6591\n",
      "Epoch 23/60\n",
      "5076/5076 [==============================] - 3s 624us/step - loss: 0.3010 - acc: 0.8855 - val_loss: 1.3923 - val_acc: 0.6709\n",
      "Epoch 24/60\n",
      "5076/5076 [==============================] - 3s 625us/step - loss: 0.2852 - acc: 0.8907 - val_loss: 1.4668 - val_acc: 0.5472\n",
      "Epoch 25/60\n",
      "5076/5076 [==============================] - 3s 626us/step - loss: 0.2753 - acc: 0.8964 - val_loss: 1.8337 - val_acc: 0.5110\n",
      "Epoch 26/60\n",
      "5076/5076 [==============================] - 3s 627us/step - loss: 0.2680 - acc: 0.8980 - val_loss: 1.2750 - val_acc: 0.6646\n",
      "Epoch 27/60\n",
      "5076/5076 [==============================] - 3s 626us/step - loss: 0.2571 - acc: 0.9045 - val_loss: 1.3453 - val_acc: 0.6047\n",
      "Epoch 28/60\n",
      "5076/5076 [==============================] - 3s 626us/step - loss: 0.2476 - acc: 0.9074 - val_loss: 1.8631 - val_acc: 0.5417\n",
      "Epoch 29/60\n",
      "5076/5076 [==============================] - 3s 625us/step - loss: 0.2361 - acc: 0.9147 - val_loss: 1.3407 - val_acc: 0.6016\n",
      "Epoch 30/60\n",
      "5076/5076 [==============================] - 3s 625us/step - loss: 0.2332 - acc: 0.9171 - val_loss: 2.4868 - val_acc: 0.5047\n",
      "Epoch 31/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5076/5076 [==============================] - 3s 626us/step - loss: 0.2164 - acc: 0.9240 - val_loss: 1.8435 - val_acc: 0.6276\n",
      "Epoch 32/60\n",
      "5076/5076 [==============================] - 3s 625us/step - loss: 0.2136 - acc: 0.9263 - val_loss: 1.0957 - val_acc: 0.6866\n",
      "Epoch 33/60\n",
      "5076/5076 [==============================] - 3s 626us/step - loss: 0.2064 - acc: 0.9255 - val_loss: 1.5245 - val_acc: 0.6252\n",
      "Epoch 34/60\n",
      "5076/5076 [==============================] - 3s 626us/step - loss: 0.1982 - acc: 0.9346 - val_loss: 1.7415 - val_acc: 0.5535\n",
      "Epoch 35/60\n",
      "5076/5076 [==============================] - 3s 640us/step - loss: 0.1890 - acc: 0.9385 - val_loss: 2.1173 - val_acc: 0.65040.1804\n",
      "Epoch 36/60\n",
      "5076/5076 [==============================] - 3s 629us/step - loss: 0.1914 - acc: 0.9350 - val_loss: 2.0351 - val_acc: 0.5882\n",
      "Epoch 37/60\n",
      "5076/5076 [==============================] - 3s 620us/step - loss: 0.1871 - acc: 0.9340 - val_loss: 1.6476 - val_acc: 0.6724\n",
      "Epoch 38/60\n",
      "5076/5076 [==============================] - 3s 611us/step - loss: 0.1712 - acc: 0.9419 - val_loss: 2.5506 - val_acc: 0.5882\n",
      "Epoch 39/60\n",
      "5076/5076 [==============================] - 3s 620us/step - loss: 0.1725 - acc: 0.9437 - val_loss: 6.4380 - val_acc: 0.3882\n",
      "Epoch 40/60\n",
      "5076/5076 [==============================] - 3s 619us/step - loss: 0.1722 - acc: 0.9433 - val_loss: 3.0318 - val_acc: 0.6512\n",
      "Epoch 41/60\n",
      "5076/5076 [==============================] - 3s 615us/step - loss: 0.1623 - acc: 0.9456 - val_loss: 2.2098 - val_acc: 0.6551\n",
      "Epoch 42/60\n",
      "5076/5076 [==============================] - 3s 617us/step - loss: 0.1521 - acc: 0.9527 - val_loss: 3.1323 - val_acc: 0.6197\n",
      "Epoch 43/60\n",
      "5076/5076 [==============================] - 3s 617us/step - loss: 0.1456 - acc: 0.9549 - val_loss: 1.7001 - val_acc: 0.6150\n",
      "Epoch 44/60\n",
      "5076/5076 [==============================] - 3s 621us/step - loss: 0.1534 - acc: 0.9525 - val_loss: 1.8080 - val_acc: 0.6606\n",
      "Epoch 45/60\n",
      "5076/5076 [==============================] - 3s 615us/step - loss: 0.1394 - acc: 0.9576 - val_loss: 2.2381 - val_acc: 0.6173\n",
      "Epoch 46/60\n",
      "5076/5076 [==============================] - 3s 616us/step - loss: 0.1391 - acc: 0.9584 - val_loss: 2.7658 - val_acc: 0.5756\n",
      "Epoch 47/60\n",
      "5076/5076 [==============================] - 3s 613us/step - loss: 0.1457 - acc: 0.9535 - val_loss: 3.1413 - val_acc: 0.5457\n",
      "Epoch 48/60\n",
      "5076/5076 [==============================] - 3s 614us/step - loss: 0.1411 - acc: 0.9563 - val_loss: 2.2716 - val_acc: 0.6354\n",
      "Epoch 49/60\n",
      "5076/5076 [==============================] - 3s 615us/step - loss: 0.1376 - acc: 0.9594 - val_loss: 1.5872 - val_acc: 0.6299\n",
      "Epoch 50/60\n",
      "5076/5076 [==============================] - 3s 612us/step - loss: 0.1302 - acc: 0.9576 - val_loss: 2.2038 - val_acc: 0.6087\n",
      "Epoch 51/60\n",
      "5076/5076 [==============================] - 3s 610us/step - loss: 0.1259 - acc: 0.9620 - val_loss: 3.0723 - val_acc: 0.5213\n",
      "Epoch 52/60\n",
      "5076/5076 [==============================] - 3s 612us/step - loss: 0.1185 - acc: 0.9632 - val_loss: 2.2942 - val_acc: 0.6520\n",
      "Epoch 53/60\n",
      "5076/5076 [==============================] - 3s 612us/step - loss: 0.1266 - acc: 0.9636 - val_loss: 2.7621 - val_acc: 0.5134\n",
      "Epoch 54/60\n",
      "5076/5076 [==============================] - 3s 613us/step - loss: 0.1227 - acc: 0.9630 - val_loss: 2.6506 - val_acc: 0.5717\n",
      "Epoch 55/60\n",
      "5076/5076 [==============================] - 3s 613us/step - loss: 0.1195 - acc: 0.9643 - val_loss: 3.3015 - val_acc: 0.6205\n",
      "Epoch 56/60\n",
      "5076/5076 [==============================] - 3s 615us/step - loss: 0.1193 - acc: 0.9659 - val_loss: 1.9342 - val_acc: 0.6740\n",
      "Epoch 57/60\n",
      "5076/5076 [==============================] - 3s 613us/step - loss: 0.1192 - acc: 0.9651 - val_loss: 2.3862 - val_acc: 0.6024\n",
      "Epoch 58/60\n",
      "5076/5076 [==============================] - 3s 615us/step - loss: 0.1097 - acc: 0.9681 - val_loss: 2.4098 - val_acc: 0.6504\n",
      "Epoch 59/60\n",
      "5076/5076 [==============================] - 3s 617us/step - loss: 0.1068 - acc: 0.9683 - val_loss: 2.3649 - val_acc: 0.5638\n",
      "Epoch 60/60\n",
      "5076/5076 [==============================] - 3s 613us/step - loss: 0.1121 - acc: 0.9699 - val_loss: 2.0042 - val_acc: 0.6339\n",
      "Training advancement:  0 %\n",
      "HarryPotterTheOrderOfThePhoenix\n",
      "Train on 6360 samples, validate on 1591 samples\n",
      "Epoch 1/25\n",
      "6360/6360 [==============================] - 4s 619us/step - loss: 0.6109 - acc: 0.8035 - val_loss: 0.1310 - val_acc: 0.9874\n",
      "Epoch 2/25\n",
      "6360/6360 [==============================] - 4s 616us/step - loss: 0.4909 - acc: 0.8162 - val_loss: 0.2893 - val_acc: 0.9855\n",
      "Epoch 3/25\n",
      "6360/6360 [==============================] - 4s 611us/step - loss: 0.4711 - acc: 0.8176 - val_loss: 0.3769 - val_acc: 0.9566\n",
      "Epoch 4/25\n",
      "6360/6360 [==============================] - 4s 614us/step - loss: 0.4516 - acc: 0.8200 - val_loss: 0.2144 - val_acc: 0.9868\n",
      "Epoch 5/25\n",
      "6360/6360 [==============================] - 4s 613us/step - loss: 0.4244 - acc: 0.8266 - val_loss: 0.2733 - val_acc: 0.9679\n",
      "Epoch 6/25\n",
      "6360/6360 [==============================] - 4s 613us/step - loss: 0.3939 - acc: 0.8349 - val_loss: 0.3076 - val_acc: 0.8674\n",
      "Epoch 7/25\n",
      "6360/6360 [==============================] - 4s 610us/step - loss: 0.3602 - acc: 0.8579 - val_loss: 0.2521 - val_acc: 0.9353\n",
      "Epoch 8/25\n",
      "6360/6360 [==============================] - 4s 612us/step - loss: 0.3270 - acc: 0.8679 - val_loss: 1.0501 - val_acc: 0.4444\n",
      "Epoch 9/25\n",
      "6360/6360 [==============================] - 4s 612us/step - loss: 0.2869 - acc: 0.8873 - val_loss: 0.2774 - val_acc: 0.9076\n",
      "Epoch 10/25\n",
      "6360/6360 [==============================] - 4s 613us/step - loss: 0.2512 - acc: 0.9064 - val_loss: 0.2382 - val_acc: 0.9453\n",
      "Epoch 11/25\n",
      "6360/6360 [==============================] - 4s 614us/step - loss: 0.2267 - acc: 0.9179 - val_loss: 0.2390 - val_acc: 0.9302\n",
      "Epoch 12/25\n",
      "6360/6360 [==============================] - 4s 614us/step - loss: 0.2003 - acc: 0.9283 - val_loss: 0.3181 - val_acc: 0.8944\n",
      "Epoch 13/25\n",
      "6360/6360 [==============================] - 4s 613us/step - loss: 0.1795 - acc: 0.9374 - val_loss: 0.1919 - val_acc: 0.9510\n",
      "Epoch 14/25\n",
      "6360/6360 [==============================] - 4s 617us/step - loss: 0.1735 - acc: 0.9418 - val_loss: 1.3310 - val_acc: 0.7172\n",
      "Epoch 15/25\n",
      "6360/6360 [==============================] - 4s 616us/step - loss: 0.1673 - acc: 0.9418 - val_loss: 0.1962 - val_acc: 0.9573\n",
      "Epoch 16/25\n",
      "6360/6360 [==============================] - 4s 616us/step - loss: 0.1430 - acc: 0.9557 - val_loss: 0.2095 - val_acc: 0.9717\n",
      "Epoch 17/25\n",
      "6360/6360 [==============================] - 4s 612us/step - loss: 0.1373 - acc: 0.9558 - val_loss: 0.7331 - val_acc: 0.7832\n",
      "Epoch 18/25\n",
      "6360/6360 [==============================] - 4s 614us/step - loss: 0.1464 - acc: 0.9520 - val_loss: 0.2258 - val_acc: 0.9874\n",
      "Epoch 19/25\n",
      "6360/6360 [==============================] - 4s 613us/step - loss: 0.1363 - acc: 0.9582 - val_loss: 0.5383 - val_acc: 0.8586\n",
      "Epoch 20/25\n",
      "6360/6360 [==============================] - 4s 613us/step - loss: 0.1139 - acc: 0.9667 - val_loss: 0.3372 - val_acc: 0.9277\n",
      "Epoch 21/25\n",
      "6360/6360 [==============================] - 4s 616us/step - loss: 0.1151 - acc: 0.9657 - val_loss: 0.6476 - val_acc: 0.8265\n",
      "Epoch 22/25\n",
      "6360/6360 [==============================] - 4s 615us/step - loss: 0.1064 - acc: 0.9697 - val_loss: 0.5389 - val_acc: 0.8680\n",
      "Epoch 23/25\n",
      "6360/6360 [==============================] - 4s 614us/step - loss: 0.1122 - acc: 0.9643 - val_loss: 0.5237 - val_acc: 0.8762\n",
      "Epoch 24/25\n",
      "6360/6360 [==============================] - 4s 615us/step - loss: 0.1053 - acc: 0.9664 - val_loss: 1.6221 - val_acc: 0.6304\n",
      "Epoch 25/25\n",
      "6360/6360 [==============================] - 4s 611us/step - loss: 0.0978 - acc: 0.9717 - val_loss: 0.2868 - val_acc: 0.9541\n",
      "Training advancement:  0 %\n",
      "IAmLegend\n",
      "Train on 4476 samples, validate on 1119 samples\n",
      "Epoch 1/25\n",
      "4476/4476 [==============================] - 3s 634us/step - loss: 0.6391 - acc: 0.7330 - val_loss: 7.8813 - val_acc: 0.2538\n",
      "Epoch 2/25\n",
      "4476/4476 [==============================] - 3s 617us/step - loss: 0.5189 - acc: 0.7688 - val_loss: 2.8663 - val_acc: 0.3056\n",
      "Epoch 3/25\n",
      "4476/4476 [==============================] - 3s 616us/step - loss: 0.4742 - acc: 0.7987 - val_loss: 2.3773 - val_acc: 0.3351\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4476/4476 [==============================] - 3s 611us/step - loss: 0.4317 - acc: 0.8152 - val_loss: 1.3514 - val_acc: 0.4727\n",
      "Epoch 5/25\n",
      "4476/4476 [==============================] - 3s 616us/step - loss: 0.3930 - acc: 0.8374 - val_loss: 4.3291 - val_acc: 0.3003\n",
      "Epoch 6/25\n",
      "4476/4476 [==============================] - 3s 612us/step - loss: 0.3628 - acc: 0.8537 - val_loss: 2.1907 - val_acc: 0.4817\n",
      "Epoch 7/25\n",
      "4476/4476 [==============================] - 3s 613us/step - loss: 0.3357 - acc: 0.8677 - val_loss: 3.4725 - val_acc: 0.4138\n",
      "Epoch 8/25\n",
      "4476/4476 [==============================] - 3s 613us/step - loss: 0.3072 - acc: 0.8814 - val_loss: 4.4027 - val_acc: 0.3727\n",
      "Epoch 9/25\n",
      "4476/4476 [==============================] - 3s 614us/step - loss: 0.2860 - acc: 0.8948 - val_loss: 3.4082 - val_acc: 0.4066\n",
      "Epoch 10/25\n",
      "4476/4476 [==============================] - 3s 613us/step - loss: 0.2565 - acc: 0.9062 - val_loss: 4.7313 - val_acc: 0.3601\n",
      "Epoch 11/25\n",
      "4476/4476 [==============================] - 3s 612us/step - loss: 0.2473 - acc: 0.9109 - val_loss: 4.0164 - val_acc: 0.3682\n",
      "Epoch 12/25\n",
      "4476/4476 [==============================] - 3s 621us/step - loss: 0.2252 - acc: 0.9205 - val_loss: 2.6684 - val_acc: 0.4567\n",
      "Epoch 13/25\n",
      "4476/4476 [==============================] - 3s 618us/step - loss: 0.2196 - acc: 0.9254 - val_loss: 3.6343 - val_acc: 0.3217\n",
      "Epoch 14/25\n",
      "4476/4476 [==============================] - 3s 618us/step - loss: 0.2016 - acc: 0.9330 - val_loss: 2.7659 - val_acc: 0.5139\n",
      "Epoch 15/25\n",
      "4476/4476 [==============================] - 3s 612us/step - loss: 0.1969 - acc: 0.9357 - val_loss: 3.4475 - val_acc: 0.4513\n",
      "Epoch 16/25\n",
      "4476/4476 [==============================] - 3s 617us/step - loss: 0.1806 - acc: 0.9424 - val_loss: 4.8309 - val_acc: 0.3038\n",
      "Epoch 17/25\n",
      "4476/4476 [==============================] - 3s 614us/step - loss: 0.1771 - acc: 0.9475 - val_loss: 2.3260 - val_acc: 0.4906\n",
      "Epoch 18/25\n",
      "4476/4476 [==============================] - 3s 616us/step - loss: 0.1602 - acc: 0.9529 - val_loss: 3.5349 - val_acc: 0.4504\n",
      "Epoch 19/25\n",
      "4476/4476 [==============================] - 3s 612us/step - loss: 0.1628 - acc: 0.9535 - val_loss: 3.3567 - val_acc: 0.4191\n",
      "Epoch 20/25\n",
      "4476/4476 [==============================] - 3s 615us/step - loss: 0.1585 - acc: 0.9511 - val_loss: 7.2997 - val_acc: 0.2949\n",
      "Epoch 21/25\n",
      "4476/4476 [==============================] - 3s 615us/step - loss: 0.1467 - acc: 0.9542 - val_loss: 5.6028 - val_acc: 0.3190\n",
      "Epoch 22/25\n",
      "4476/4476 [==============================] - 3s 612us/step - loss: 0.1503 - acc: 0.9564 - val_loss: 5.8933 - val_acc: 0.2958\n",
      "Epoch 23/25\n",
      "4476/4476 [==============================] - 3s 627us/step - loss: 0.1461 - acc: 0.9584 - val_loss: 3.3205 - val_acc: 0.5040\n",
      "Epoch 24/25\n",
      "4476/4476 [==============================] - 3s 629us/step - loss: 0.1502 - acc: 0.9540 - val_loss: 6.3191 - val_acc: 0.3718\n",
      "Epoch 25/25\n",
      "4476/4476 [==============================] - 3s 620us/step - loss: 0.1385 - acc: 0.9596 - val_loss: 5.3664 - val_acc: 0.3709\n",
      "Training advancement:  0 %\n",
      "PiratesOfTheCarribeanTheCurseOfTheBlackPearl\n",
      "Train on 6590 samples, validate on 1648 samples\n",
      "Epoch 1/25\n",
      "6590/6590 [==============================] - 4s 629us/step - loss: 0.6648 - acc: 0.7294 - val_loss: 0.5554 - val_acc: 0.7894\n",
      "Epoch 2/25\n",
      "6590/6590 [==============================] - 4s 614us/step - loss: 0.5807 - acc: 0.7428 - val_loss: 1.5461 - val_acc: 0.7900\n",
      "Epoch 3/25\n",
      "6590/6590 [==============================] - 4s 615us/step - loss: 0.5620 - acc: 0.7455 - val_loss: 1.2324 - val_acc: 0.7907\n",
      "Epoch 4/25\n",
      "6590/6590 [==============================] - 4s 613us/step - loss: 0.5420 - acc: 0.7517 - val_loss: 2.4501 - val_acc: 0.2992\n",
      "Epoch 5/25\n",
      "6590/6590 [==============================] - 4s 614us/step - loss: 0.5219 - acc: 0.7669 - val_loss: 1.7220 - val_acc: 0.7900\n",
      "Epoch 6/25\n",
      "6590/6590 [==============================] - 4s 617us/step - loss: 0.4999 - acc: 0.7753 - val_loss: 0.7293 - val_acc: 0.7937\n",
      "Epoch 7/25\n",
      "6590/6590 [==============================] - 4s 619us/step - loss: 0.4704 - acc: 0.7944 - val_loss: 0.7202 - val_acc: 0.7816\n",
      "Epoch 8/25\n",
      "6590/6590 [==============================] - 4s 618us/step - loss: 0.4423 - acc: 0.8064 - val_loss: 0.8396 - val_acc: 0.7585\n",
      "Epoch 9/25\n",
      "6590/6590 [==============================] - 4s 620us/step - loss: 0.4202 - acc: 0.8212 - val_loss: 1.2519 - val_acc: 0.6893\n",
      "Epoch 10/25\n",
      "6590/6590 [==============================] - 4s 619us/step - loss: 0.3935 - acc: 0.8378 - val_loss: 1.4543 - val_acc: 0.7785\n",
      "Epoch 11/25\n",
      "6590/6590 [==============================] - 4s 622us/step - loss: 0.3737 - acc: 0.8445 - val_loss: 2.0832 - val_acc: 0.7900\n",
      "Epoch 12/25\n",
      "6590/6590 [==============================] - 5s 688us/step - loss: 0.3519 - acc: 0.8546 - val_loss: 0.7910 - val_acc: 0.7445\n",
      "Epoch 13/25\n",
      "6590/6590 [==============================] - 4s 623us/step - loss: 0.3304 - acc: 0.8660 - val_loss: 1.2987 - val_acc: 0.7797\n",
      "Epoch 14/25\n",
      "6590/6590 [==============================] - 4s 667us/step - loss: 0.3143 - acc: 0.8727 - val_loss: 1.5561 - val_acc: 0.7797\n",
      "Epoch 15/25\n",
      "6590/6590 [==============================] - 4s 651us/step - loss: 0.2928 - acc: 0.8827 - val_loss: 1.2635 - val_acc: 0.7828\n",
      "Epoch 16/25\n",
      "6590/6590 [==============================] - 5s 690us/step - loss: 0.2759 - acc: 0.8948 - val_loss: 2.5419 - val_acc: 0.7907\n",
      "Epoch 17/25\n",
      "6590/6590 [==============================] - 4s 671us/step - loss: 0.2668 - acc: 0.8982 - val_loss: 2.8440 - val_acc: 0.7919\n",
      "Epoch 18/25\n",
      "6590/6590 [==============================] - 4s 620us/step - loss: 0.2550 - acc: 0.9017 - val_loss: 1.0728 - val_acc: 0.7075\n",
      "Epoch 19/25\n",
      "6590/6590 [==============================] - 4s 641us/step - loss: 0.2456 - acc: 0.9070 - val_loss: 1.7583 - val_acc: 0.7609\n",
      "Epoch 20/25\n",
      "6590/6590 [==============================] - 4s 623us/step - loss: 0.2330 - acc: 0.9135 - val_loss: 1.7945 - val_acc: 0.7008\n",
      "Epoch 21/25\n",
      "6590/6590 [==============================] - 4s 615us/step - loss: 0.2152 - acc: 0.9217 - val_loss: 1.4933 - val_acc: 0.7603\n",
      "Epoch 22/25\n",
      "6590/6590 [==============================] - 4s 616us/step - loss: 0.2041 - acc: 0.9258 - val_loss: 3.2686 - val_acc: 0.7900\n",
      "Epoch 23/25\n",
      "6590/6590 [==============================] - 4s 617us/step - loss: 0.1953 - acc: 0.9300 - val_loss: 2.4543 - val_acc: 0.7870\n",
      "Epoch 24/25\n",
      "6590/6590 [==============================] - 4s 616us/step - loss: 0.1868 - acc: 0.9393 - val_loss: 2.0039 - val_acc: 0.7227\n",
      "Epoch 25/25\n",
      "6590/6590 [==============================] - 4s 613us/step - loss: 0.1828 - acc: 0.9376 - val_loss: 2.8404 - val_acc: 0.7925\n",
      "Training advancement:  0 %\n",
      "TheSixthSense\n",
      "Train on 4939 samples, validate on 1235 samples\n",
      "Epoch 1/60\n",
      "4939/4939 [==============================] - 3s 631us/step - loss: 0.7820 - acc: 0.5416 - val_loss: 0.7575 - val_acc: 0.3377\n",
      "Epoch 2/60\n",
      "4939/4939 [==============================] - 3s 625us/step - loss: 0.6864 - acc: 0.5886 - val_loss: 0.8545 - val_acc: 0.2227\n",
      "Epoch 3/60\n",
      "4939/4939 [==============================] - 3s 619us/step - loss: 0.6587 - acc: 0.6273 - val_loss: 0.5870 - val_acc: 0.7806\n",
      "Epoch 4/60\n",
      "4939/4939 [==============================] - 3s 615us/step - loss: 0.6383 - acc: 0.6526 - val_loss: 0.9143 - val_acc: 0.3879\n",
      "Epoch 5/60\n",
      "4939/4939 [==============================] - 3s 616us/step - loss: 0.6126 - acc: 0.6688 - val_loss: 4.8815 - val_acc: 0.1142\n",
      "Epoch 6/60\n",
      "4939/4939 [==============================] - 3s 616us/step - loss: 0.5889 - acc: 0.6880 - val_loss: 0.7170 - val_acc: 0.7700\n",
      "Epoch 7/60\n",
      "4939/4939 [==============================] - 3s 620us/step - loss: 0.5645 - acc: 0.7028 - val_loss: 1.2331 - val_acc: 0.4324\n",
      "Epoch 8/60\n",
      "4939/4939 [==============================] - 3s 624us/step - loss: 0.5444 - acc: 0.7174 - val_loss: 1.5116 - val_acc: 0.5126\n",
      "Epoch 9/60\n",
      "4939/4939 [==============================] - 3s 617us/step - loss: 0.5113 - acc: 0.7471 - val_loss: 1.0128 - val_acc: 0.6640\n",
      "Epoch 10/60\n",
      "4939/4939 [==============================] - 3s 615us/step - loss: 0.5105 - acc: 0.7384 - val_loss: 10.7046 - val_acc: 0.1061\n",
      "Epoch 11/60\n",
      "4939/4939 [==============================] - 3s 613us/step - loss: 0.4790 - acc: 0.7666 - val_loss: 1.9099 - val_acc: 0.5919\n",
      "Epoch 12/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4939/4939 [==============================] - 3s 617us/step - loss: 0.4621 - acc: 0.7779 - val_loss: 7.7467 - val_acc: 0.2356\n",
      "Epoch 13/60\n",
      "4939/4939 [==============================] - 3s 615us/step - loss: 0.4464 - acc: 0.7821 - val_loss: 1.8774 - val_acc: 0.5652\n",
      "Epoch 14/60\n",
      "4939/4939 [==============================] - 3s 614us/step - loss: 0.4320 - acc: 0.7882 - val_loss: 0.9657 - val_acc: 0.8130\n",
      "Epoch 15/60\n",
      "4939/4939 [==============================] - 3s 612us/step - loss: 0.4208 - acc: 0.7996 - val_loss: 1.7305 - val_acc: 0.4713\n",
      "Epoch 16/60\n",
      "4939/4939 [==============================] - 3s 615us/step - loss: 0.4076 - acc: 0.8042 - val_loss: 2.8002 - val_acc: 0.3312\n",
      "Epoch 17/60\n",
      "4939/4939 [==============================] - 3s 615us/step - loss: 0.3852 - acc: 0.8194 - val_loss: 12.2294 - val_acc: 0.1174\n",
      "Epoch 18/60\n",
      "4939/4939 [==============================] - 3s 614us/step - loss: 0.3805 - acc: 0.8245 - val_loss: 2.9584 - val_acc: 0.3717\n",
      "Epoch 19/60\n",
      "4939/4939 [==============================] - 3s 614us/step - loss: 0.3798 - acc: 0.8236 - val_loss: 1.7892 - val_acc: 0.4769\n",
      "Epoch 20/60\n",
      "4939/4939 [==============================] - 3s 613us/step - loss: 0.3571 - acc: 0.8352 - val_loss: 3.7896 - val_acc: 0.3077\n",
      "Epoch 21/60\n",
      "4939/4939 [==============================] - 3s 614us/step - loss: 0.3527 - acc: 0.8413 - val_loss: 1.6306 - val_acc: 0.6777\n",
      "Epoch 22/60\n",
      "4939/4939 [==============================] - 3s 613us/step - loss: 0.3335 - acc: 0.8508 - val_loss: 2.9083 - val_acc: 0.5053\n",
      "Epoch 23/60\n",
      "4939/4939 [==============================] - 3s 640us/step - loss: 0.3352 - acc: 0.8490 - val_loss: 2.0855 - val_acc: 0.5636\n",
      "Epoch 24/60\n",
      "4939/4939 [==============================] - 3s 639us/step - loss: 0.3175 - acc: 0.8589 - val_loss: 2.2788 - val_acc: 0.4543\n",
      "Epoch 25/60\n",
      "4939/4939 [==============================] - 3s 625us/step - loss: 0.3237 - acc: 0.8558 - val_loss: 2.6705 - val_acc: 0.3781\n",
      "Epoch 26/60\n",
      "4939/4939 [==============================] - 3s 632us/step - loss: 0.3033 - acc: 0.8684 - val_loss: 1.5117 - val_acc: 0.6802\n",
      "Epoch 27/60\n",
      "4939/4939 [==============================] - 3s 627us/step - loss: 0.2953 - acc: 0.8743 - val_loss: 3.5472 - val_acc: 0.4162\n",
      "Epoch 28/60\n",
      "4939/4939 [==============================] - 3s 624us/step - loss: 0.2891 - acc: 0.8733 - val_loss: 1.5533 - val_acc: 0.6324\n",
      "Epoch 29/60\n",
      "4939/4939 [==============================] - 3s 625us/step - loss: 0.2809 - acc: 0.8834 - val_loss: 1.7860 - val_acc: 0.5538\n",
      "Epoch 30/60\n",
      "4939/4939 [==============================] - 3s 627us/step - loss: 0.2811 - acc: 0.8822 - val_loss: 1.7061 - val_acc: 0.5279\n",
      "Epoch 31/60\n",
      "4939/4939 [==============================] - 3s 621us/step - loss: 0.2767 - acc: 0.8882 - val_loss: 5.3560 - val_acc: 0.4599\n",
      "Epoch 32/60\n",
      "4939/4939 [==============================] - 3s 623us/step - loss: 0.2734 - acc: 0.8876 - val_loss: 2.2123 - val_acc: 0.4372\n",
      "Epoch 33/60\n",
      "4939/4939 [==============================] - 3s 624us/step - loss: 0.2559 - acc: 0.8988 - val_loss: 2.8846 - val_acc: 0.4324\n",
      "Epoch 34/60\n",
      "4939/4939 [==============================] - 3s 702us/step - loss: 0.2355 - acc: 0.9046 - val_loss: 4.2612 - val_acc: 0.4372\n",
      "Epoch 35/60\n",
      "4939/4939 [==============================] - 3s 670us/step - loss: 0.2482 - acc: 0.9040 - val_loss: 3.9659 - val_acc: 0.3927\n",
      "Epoch 36/60\n",
      "4939/4939 [==============================] - 3s 656us/step - loss: 0.2425 - acc: 0.9034 - val_loss: 2.2181 - val_acc: 0.5482\n",
      "Epoch 37/60\n",
      "4939/4939 [==============================] - 3s 645us/step - loss: 0.2295 - acc: 0.9109 - val_loss: 2.8820 - val_acc: 0.5142: 0s - loss: 0.2265 - acc: 0.\n",
      "Epoch 38/60\n",
      "4939/4939 [==============================] - 3s 626us/step - loss: 0.2347 - acc: 0.9065 - val_loss: 9.6591 - val_acc: 0.2049\n",
      "Epoch 39/60\n",
      "4939/4939 [==============================] - 3s 628us/step - loss: 0.2206 - acc: 0.9192 - val_loss: 3.3769 - val_acc: 0.4486\n",
      "Epoch 40/60\n",
      "4939/4939 [==============================] - 3s 627us/step - loss: 0.2109 - acc: 0.9231 - val_loss: 2.7281 - val_acc: 0.4883\n",
      "Epoch 41/60\n",
      "4939/4939 [==============================] - 3s 617us/step - loss: 0.2143 - acc: 0.9196 - val_loss: 2.9309 - val_acc: 0.5368\n",
      "Epoch 42/60\n",
      "4939/4939 [==============================] - 3s 619us/step - loss: 0.2180 - acc: 0.9192 - val_loss: 6.6463 - val_acc: 0.2397\n",
      "Epoch 43/60\n",
      "4939/4939 [==============================] - 3s 616us/step - loss: 0.2038 - acc: 0.9257 - val_loss: 2.1244 - val_acc: 0.5709\n",
      "Epoch 44/60\n",
      "4939/4939 [==============================] - 3s 614us/step - loss: 0.1965 - acc: 0.9273 - val_loss: 1.6223 - val_acc: 0.8818\n",
      "Epoch 45/60\n",
      "4939/4939 [==============================] - 3s 613us/step - loss: 0.2031 - acc: 0.9243 - val_loss: 3.1520 - val_acc: 0.5555\n",
      "Epoch 46/60\n",
      "4939/4939 [==============================] - 3s 617us/step - loss: 0.1956 - acc: 0.9297 - val_loss: 2.6458 - val_acc: 0.4907\n",
      "Epoch 47/60\n",
      "4939/4939 [==============================] - 3s 620us/step - loss: 0.1860 - acc: 0.9334 - val_loss: 3.9023 - val_acc: 0.4057\n",
      "Epoch 48/60\n",
      "4939/4939 [==============================] - 3s 617us/step - loss: 0.1916 - acc: 0.9316 - val_loss: 1.9614 - val_acc: 0.6097\n",
      "Epoch 49/60\n",
      "4939/4939 [==============================] - 3s 624us/step - loss: 0.1811 - acc: 0.9326 - val_loss: 2.3707 - val_acc: 0.7190\n",
      "Epoch 50/60\n",
      "4939/4939 [==============================] - 3s 613us/step - loss: 0.1708 - acc: 0.9409 - val_loss: 5.6980 - val_acc: 0.3182\n",
      "Epoch 51/60\n",
      "4939/4939 [==============================] - 3s 616us/step - loss: 0.1627 - acc: 0.9461 - val_loss: 1.3855 - val_acc: 0.8640\n",
      "Epoch 52/60\n",
      "4939/4939 [==============================] - 3s 612us/step - loss: 0.1539 - acc: 0.9482 - val_loss: 5.1412 - val_acc: 0.3223\n",
      "Epoch 53/60\n",
      "4939/4939 [==============================] - 3s 614us/step - loss: 0.1729 - acc: 0.9423 - val_loss: 4.0221 - val_acc: 0.4818\n",
      "Epoch 54/60\n",
      "4939/4939 [==============================] - 3s 613us/step - loss: 0.1619 - acc: 0.9500 - val_loss: 5.4037 - val_acc: 0.2858\n",
      "Epoch 55/60\n",
      "4939/4939 [==============================] - 3s 613us/step - loss: 0.1534 - acc: 0.9490 - val_loss: 2.4813 - val_acc: 0.5077\n",
      "Epoch 56/60\n",
      "4939/4939 [==============================] - 3s 613us/step - loss: 0.1646 - acc: 0.9463 - val_loss: 1.7856 - val_acc: 0.7352\n",
      "Epoch 57/60\n",
      "4939/4939 [==============================] - 3s 614us/step - loss: 0.1580 - acc: 0.9480 - val_loss: 5.2538 - val_acc: 0.3927\n",
      "Epoch 58/60\n",
      "4939/4939 [==============================] - 3s 617us/step - loss: 0.1395 - acc: 0.9561 - val_loss: 2.7806 - val_acc: 0.5530\n",
      "Epoch 59/60\n",
      "4939/4939 [==============================] - 3s 623us/step - loss: 0.1611 - acc: 0.9496 - val_loss: 1.6530 - val_acc: 0.8178\n",
      "Epoch 60/60\n",
      "4939/4939 [==============================] - 3s 616us/step - loss: 0.1520 - acc: 0.9551 - val_loss: 4.4157 - val_acc: 0.3498\n",
      "Training advancement:  0 %\n",
      "FightClub\n",
      "Train on 6396 samples, validate on 1599 samples\n",
      "Epoch 1/25\n",
      "6396/6396 [==============================] - 4s 615us/step - loss: 0.7730 - acc: 0.7006 - val_loss: 1.3063 - val_acc: 0.5804\n",
      "Epoch 2/25\n",
      "6396/6396 [==============================] - 4s 616us/step - loss: 0.5868 - acc: 0.7342 - val_loss: 0.6541 - val_acc: 0.7129\n",
      "Epoch 3/25\n",
      "6396/6396 [==============================] - 4s 612us/step - loss: 0.5602 - acc: 0.7453 - val_loss: 3.3710 - val_acc: 0.1751\n",
      "Epoch 4/25\n",
      "6396/6396 [==============================] - 4s 610us/step - loss: 0.5345 - acc: 0.7586 - val_loss: 1.4263 - val_acc: 0.3171\n",
      "Epoch 5/25\n",
      "6396/6396 [==============================] - 4s 612us/step - loss: 0.5201 - acc: 0.7664 - val_loss: 0.5550 - val_acc: 0.8311\n",
      "Epoch 6/25\n",
      "6396/6396 [==============================] - 4s 611us/step - loss: 0.4941 - acc: 0.7769 - val_loss: 0.6603 - val_acc: 0.9575\n",
      "Epoch 7/25\n",
      "6396/6396 [==============================] - 4s 612us/step - loss: 0.4757 - acc: 0.7849 - val_loss: 0.7329 - val_acc: 0.9074\n",
      "Epoch 8/25\n",
      "6396/6396 [==============================] - 4s 613us/step - loss: 0.4527 - acc: 0.7977 - val_loss: 0.6449 - val_acc: 0.9575\n",
      "Epoch 9/25\n",
      "6396/6396 [==============================] - 4s 612us/step - loss: 0.4363 - acc: 0.8047 - val_loss: 0.4418 - val_acc: 0.9062\n",
      "Epoch 10/25\n",
      "6396/6396 [==============================] - 4s 610us/step - loss: 0.4104 - acc: 0.8185 - val_loss: 3.7736 - val_acc: 0.3133\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6396/6396 [==============================] - 4s 610us/step - loss: 0.3952 - acc: 0.8258 - val_loss: 0.6568 - val_acc: 0.9575\n",
      "Epoch 12/25\n",
      "6396/6396 [==============================] - 4s 611us/step - loss: 0.3709 - acc: 0.8336 - val_loss: 1.0066 - val_acc: 0.7661\n",
      "Epoch 13/25\n",
      "6396/6396 [==============================] - 4s 611us/step - loss: 0.3603 - acc: 0.8455 - val_loss: 0.7544 - val_acc: 0.7511\n",
      "Epoch 14/25\n",
      "6396/6396 [==============================] - 4s 616us/step - loss: 0.3250 - acc: 0.8679 - val_loss: 0.6027 - val_acc: 0.9400\n",
      "Epoch 15/25\n",
      "6396/6396 [==============================] - 4s 618us/step - loss: 0.3204 - acc: 0.8674 - val_loss: 0.5526 - val_acc: 0.9362\n",
      "Epoch 16/25\n",
      "6396/6396 [==============================] - 4s 614us/step - loss: 0.3015 - acc: 0.8779 - val_loss: 0.7728 - val_acc: 0.8049\n",
      "Epoch 17/25\n",
      "6396/6396 [==============================] - 4s 610us/step - loss: 0.3418 - acc: 0.8576 - val_loss: 0.6733 - val_acc: 0.9575\n",
      "Epoch 18/25\n",
      "6396/6396 [==============================] - 4s 611us/step - loss: 0.3060 - acc: 0.8727 - val_loss: 1.4783 - val_acc: 0.6623\n",
      "Epoch 19/25\n",
      "6396/6396 [==============================] - 4s 612us/step - loss: 0.2818 - acc: 0.8845 - val_loss: 0.5888 - val_acc: 0.8755\n",
      "Epoch 20/25\n",
      "6396/6396 [==============================] - 4s 614us/step - loss: 0.2591 - acc: 0.8963 - val_loss: 1.0281 - val_acc: 0.7561\n",
      "Epoch 21/25\n",
      "6396/6396 [==============================] - 4s 617us/step - loss: 0.2562 - acc: 0.8952 - val_loss: 0.8271 - val_acc: 0.7580\n",
      "Epoch 22/25\n",
      "6396/6396 [==============================] - 4s 611us/step - loss: 0.2380 - acc: 0.9074 - val_loss: 1.0850 - val_acc: 0.8305\n",
      "Epoch 23/25\n",
      "6396/6396 [==============================] - 4s 612us/step - loss: 0.2346 - acc: 0.9137 - val_loss: 0.7057 - val_acc: 0.9575\n",
      "Epoch 24/25\n",
      "6396/6396 [==============================] - 4s 614us/step - loss: 0.2176 - acc: 0.9198 - val_loss: 0.7248 - val_acc: 0.9493\n",
      "Epoch 25/25\n",
      "6396/6396 [==============================] - 4s 611us/step - loss: 0.2046 - acc: 0.9248 - val_loss: 0.8478 - val_acc: 0.8605\n",
      "Training advancement:  0 %\n",
      "TheWickerMan\n",
      "Train on 4693 samples, validate on 1174 samples\n",
      "Epoch 1/60\n",
      "4693/4693 [==============================] - 3s 680us/step - loss: 0.7420 - acc: 0.5892 - val_loss: 0.7929 - val_acc: 0.3782\n",
      "Epoch 2/60\n",
      "4693/4693 [==============================] - 3s 616us/step - loss: 0.6762 - acc: 0.6326 - val_loss: 0.7821 - val_acc: 0.4617\n",
      "Epoch 3/60\n",
      "4693/4693 [==============================] - 3s 617us/step - loss: 0.6602 - acc: 0.6446 - val_loss: 0.7289 - val_acc: 0.5468\n",
      "Epoch 4/60\n",
      "4693/4693 [==============================] - 3s 614us/step - loss: 0.6487 - acc: 0.6499 - val_loss: 0.8945 - val_acc: 0.6107\n",
      "Epoch 5/60\n",
      "4693/4693 [==============================] - 3s 615us/step - loss: 0.6358 - acc: 0.6540 - val_loss: 1.1524 - val_acc: 0.6107\n",
      "Epoch 6/60\n",
      "4693/4693 [==============================] - 3s 623us/step - loss: 0.6237 - acc: 0.6742 - val_loss: 1.0785 - val_acc: 0.6397\n",
      "Epoch 7/60\n",
      "4693/4693 [==============================] - 3s 619us/step - loss: 0.6137 - acc: 0.6750 - val_loss: 1.0476 - val_acc: 0.6022\n",
      "Epoch 8/60\n",
      "4693/4693 [==============================] - 3s 612us/step - loss: 0.5953 - acc: 0.6853 - val_loss: 0.7832 - val_acc: 0.5562\n",
      "Epoch 9/60\n",
      "4693/4693 [==============================] - 3s 614us/step - loss: 0.5815 - acc: 0.6934 - val_loss: 1.2596 - val_acc: 0.5954\n",
      "Epoch 10/60\n",
      "4693/4693 [==============================] - 3s 616us/step - loss: 0.5756 - acc: 0.6955 - val_loss: 1.0552 - val_acc: 0.5869\n",
      "Epoch 11/60\n",
      "4693/4693 [==============================] - 3s 620us/step - loss: 0.5599 - acc: 0.7104 - val_loss: 1.8357 - val_acc: 0.5503\n",
      "Epoch 12/60\n",
      "4693/4693 [==============================] - 3s 617us/step - loss: 0.5453 - acc: 0.7189 - val_loss: 1.7484 - val_acc: 0.4600\n",
      "Epoch 13/60\n",
      "4693/4693 [==============================] - 3s 621us/step - loss: 0.5328 - acc: 0.7343 - val_loss: 2.0658 - val_acc: 0.5690\n",
      "Epoch 14/60\n",
      "4693/4693 [==============================] - 3s 621us/step - loss: 0.5123 - acc: 0.7481 - val_loss: 1.9689 - val_acc: 0.4532\n",
      "Epoch 15/60\n",
      "4693/4693 [==============================] - 3s 625us/step - loss: 0.5095 - acc: 0.7537 - val_loss: 1.6991 - val_acc: 0.6099\n",
      "Epoch 16/60\n",
      "4693/4693 [==============================] - 3s 636us/step - loss: 0.4837 - acc: 0.7611 - val_loss: 1.7258 - val_acc: 0.5647\n",
      "Epoch 17/60\n",
      "4693/4693 [==============================] - 3s 630us/step - loss: 0.4724 - acc: 0.7694 - val_loss: 3.8597 - val_acc: 0.6303\n",
      "Epoch 18/60\n",
      "4693/4693 [==============================] - 3s 631us/step - loss: 0.4666 - acc: 0.7743 - val_loss: 1.8677 - val_acc: 0.6576\n",
      "Epoch 19/60\n",
      "4693/4693 [==============================] - 3s 634us/step - loss: 0.4601 - acc: 0.7750 - val_loss: 1.9331 - val_acc: 0.5162\n",
      "Epoch 20/60\n",
      "4693/4693 [==============================] - 3s 631us/step - loss: 0.4324 - acc: 0.7931 - val_loss: 2.0138 - val_acc: 0.6525\n",
      "Epoch 21/60\n",
      "4693/4693 [==============================] - 3s 623us/step - loss: 0.4291 - acc: 0.8010 - val_loss: 1.7714 - val_acc: 0.5843\n",
      "Epoch 22/60\n",
      "4693/4693 [==============================] - 3s 621us/step - loss: 0.4054 - acc: 0.8112 - val_loss: 1.4753 - val_acc: 0.4940\n",
      "Epoch 23/60\n",
      "4693/4693 [==============================] - 3s 630us/step - loss: 0.4042 - acc: 0.8150 - val_loss: 2.1320 - val_acc: 0.4727\n",
      "Epoch 24/60\n",
      "4693/4693 [==============================] - 3s 636us/step - loss: 0.3914 - acc: 0.8178 - val_loss: 1.7276 - val_acc: 0.5758\n",
      "Epoch 25/60\n",
      "4693/4693 [==============================] - 3s 630us/step - loss: 0.3877 - acc: 0.8280 - val_loss: 1.8425 - val_acc: 0.5988\n",
      "Epoch 26/60\n",
      "4693/4693 [==============================] - 3s 629us/step - loss: 0.3691 - acc: 0.8312 - val_loss: 6.7557 - val_acc: 0.4106\n",
      "Epoch 27/60\n",
      "4693/4693 [==============================] - 3s 643us/step - loss: 0.3622 - acc: 0.8374 - val_loss: 6.5264 - val_acc: 0.3978\n",
      "Epoch 28/60\n",
      "4693/4693 [==============================] - 3s 627us/step - loss: 0.3646 - acc: 0.8419 - val_loss: 5.5514 - val_acc: 0.3807\n",
      "Epoch 29/60\n",
      "4693/4693 [==============================] - 3s 619us/step - loss: 0.3403 - acc: 0.8515 - val_loss: 3.5696 - val_acc: 0.4702\n",
      "Epoch 30/60\n",
      "4693/4693 [==============================] - 3s 619us/step - loss: 0.3419 - acc: 0.8515 - val_loss: 2.5231 - val_acc: 0.5716\n",
      "Epoch 31/60\n",
      "4693/4693 [==============================] - 3s 619us/step - loss: 0.3385 - acc: 0.8568 - val_loss: 1.8155 - val_acc: 0.5434\n",
      "Epoch 32/60\n",
      "4693/4693 [==============================] - 3s 623us/step - loss: 0.3140 - acc: 0.8715 - val_loss: 2.2266 - val_acc: 0.4455\n",
      "Epoch 33/60\n",
      "4693/4693 [==============================] - 3s 612us/step - loss: 0.3183 - acc: 0.8658 - val_loss: 2.6658 - val_acc: 0.5239\n",
      "Epoch 34/60\n",
      "4693/4693 [==============================] - 3s 621us/step - loss: 0.3122 - acc: 0.8713 - val_loss: 3.8646 - val_acc: 0.4514\n",
      "Epoch 35/60\n",
      "4693/4693 [==============================] - 3s 617us/step - loss: 0.3148 - acc: 0.8690 - val_loss: 4.3924 - val_acc: 0.4864\n",
      "Epoch 36/60\n",
      "4693/4693 [==============================] - 3s 615us/step - loss: 0.2852 - acc: 0.8875 - val_loss: 3.1080 - val_acc: 0.6031\n",
      "Epoch 37/60\n",
      "4693/4693 [==============================] - 3s 615us/step - loss: 0.2859 - acc: 0.8839 - val_loss: 3.3949 - val_acc: 0.5051\n",
      "Epoch 38/60\n",
      "4693/4693 [==============================] - 3s 612us/step - loss: 0.2795 - acc: 0.8898 - val_loss: 2.7602 - val_acc: 0.5460\n",
      "Epoch 39/60\n",
      "4693/4693 [==============================] - 3s 612us/step - loss: 0.2688 - acc: 0.8939 - val_loss: 2.1389 - val_acc: 0.5886\n",
      "Epoch 40/60\n",
      "4693/4693 [==============================] - 3s 613us/step - loss: 0.2749 - acc: 0.8960 - val_loss: 3.5199 - val_acc: 0.4233\n",
      "Epoch 41/60\n",
      "4693/4693 [==============================] - 3s 613us/step - loss: 0.2588 - acc: 0.8954 - val_loss: 2.3605 - val_acc: 0.5477\n",
      "Epoch 42/60\n",
      "4693/4693 [==============================] - 3s 612us/step - loss: 0.2492 - acc: 0.9007 - val_loss: 2.1245 - val_acc: 0.5877\n",
      "Epoch 43/60\n",
      "4693/4693 [==============================] - 3s 615us/step - loss: 0.2456 - acc: 0.9079 - val_loss: 2.8012 - val_acc: 0.5511\n",
      "Epoch 44/60\n",
      "4693/4693 [==============================] - 3s 616us/step - loss: 0.2436 - acc: 0.9043 - val_loss: 2.4244 - val_acc: 0.5111\n",
      "Epoch 45/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4693/4693 [==============================] - 3s 610us/step - loss: 0.2468 - acc: 0.9103 - val_loss: 3.1237 - val_acc: 0.4600\n",
      "Epoch 46/60\n",
      "4693/4693 [==============================] - 3s 614us/step - loss: 0.2239 - acc: 0.9150 - val_loss: 3.1929 - val_acc: 0.5162\n",
      "Epoch 47/60\n",
      "4693/4693 [==============================] - 3s 613us/step - loss: 0.2405 - acc: 0.9154 - val_loss: 2.4744 - val_acc: 0.5264\n",
      "Epoch 48/60\n",
      "4693/4693 [==============================] - 3s 613us/step - loss: 0.2240 - acc: 0.9177 - val_loss: 2.3457 - val_acc: 0.5928\n",
      "Epoch 49/60\n",
      "4693/4693 [==============================] - 3s 616us/step - loss: 0.2189 - acc: 0.9214 - val_loss: 4.3223 - val_acc: 0.4881\n",
      "Epoch 50/60\n",
      "4693/4693 [==============================] - 3s 614us/step - loss: 0.2251 - acc: 0.9212 - val_loss: 3.4576 - val_acc: 0.4046\n",
      "Epoch 51/60\n",
      "4693/4693 [==============================] - 3s 611us/step - loss: 0.2024 - acc: 0.9316 - val_loss: 2.4105 - val_acc: 0.5656\n",
      "Epoch 52/60\n",
      "4693/4693 [==============================] - 3s 611us/step - loss: 0.2064 - acc: 0.9276 - val_loss: 3.3204 - val_acc: 0.6252\n",
      "Epoch 53/60\n",
      "4693/4693 [==============================] - 3s 611us/step - loss: 0.2051 - acc: 0.9282 - val_loss: 2.7734 - val_acc: 0.5860\n",
      "Epoch 54/60\n",
      "4693/4693 [==============================] - 3s 615us/step - loss: 0.1969 - acc: 0.9335 - val_loss: 3.0889 - val_acc: 0.6261\n",
      "Epoch 55/60\n",
      "4693/4693 [==============================] - 3s 614us/step - loss: 0.1956 - acc: 0.9299 - val_loss: 4.0612 - val_acc: 0.5911\n",
      "Epoch 56/60\n",
      "4693/4693 [==============================] - 3s 615us/step - loss: 0.1982 - acc: 0.9344 - val_loss: 3.6698 - val_acc: 0.5835\n",
      "Epoch 57/60\n",
      "4693/4693 [==============================] - 3s 611us/step - loss: 0.1834 - acc: 0.9412 - val_loss: 3.7938 - val_acc: 0.5579\n",
      "Epoch 58/60\n",
      "4693/4693 [==============================] - 3s 615us/step - loss: 0.1816 - acc: 0.9403 - val_loss: 5.2113 - val_acc: 0.4991\n",
      "Epoch 59/60\n",
      "4693/4693 [==============================] - 3s 628us/step - loss: 0.1759 - acc: 0.9440 - val_loss: 3.3636 - val_acc: 0.5596\n",
      "Epoch 60/60\n",
      "4693/4693 [==============================] - 3s 618us/step - loss: 0.1895 - acc: 0.9382 - val_loss: 3.2167 - val_acc: 0.4898\n",
      "Training advancement:  0 %\n",
      "TheWizardOfOz\n",
      "Train on 4681 samples, validate on 1171 samples\n",
      "Epoch 1/60\n",
      "4681/4681 [==============================] - 3s 631us/step - loss: 0.8747 - acc: 0.6915 - val_loss: 0.5387 - val_acc: 0.8258\n",
      "Epoch 2/60\n",
      "4681/4681 [==============================] - 3s 641us/step - loss: 0.6300 - acc: 0.7110 - val_loss: 0.7550 - val_acc: 0.8249\n",
      "Epoch 3/60\n",
      "4681/4681 [==============================] - 3s 615us/step - loss: 0.6122 - acc: 0.7135 - val_loss: 0.4798 - val_acc: 0.8249\n",
      "Epoch 4/60\n",
      "4681/4681 [==============================] - 3s 615us/step - loss: 0.5957 - acc: 0.7238 - val_loss: 0.6481 - val_acc: 0.8249\n",
      "Epoch 5/60\n",
      "4681/4681 [==============================] - 3s 614us/step - loss: 0.5723 - acc: 0.7332 - val_loss: 0.6318 - val_acc: 0.7105\n",
      "Epoch 6/60\n",
      "4681/4681 [==============================] - 3s 616us/step - loss: 0.5557 - acc: 0.7385 - val_loss: 0.7339 - val_acc: 0.6354\n",
      "Epoch 7/60\n",
      "4681/4681 [==============================] - 3s 615us/step - loss: 0.5396 - acc: 0.7490 - val_loss: 1.4510 - val_acc: 0.8258\n",
      "Epoch 8/60\n",
      "4681/4681 [==============================] - 3s 617us/step - loss: 0.5222 - acc: 0.7586 - val_loss: 0.6842 - val_acc: 0.8070\n",
      "Epoch 9/60\n",
      "4681/4681 [==============================] - 3s 616us/step - loss: 0.5025 - acc: 0.7697 - val_loss: 0.7724 - val_acc: 0.8266\n",
      "Epoch 10/60\n",
      "4681/4681 [==============================] - 3s 616us/step - loss: 0.4925 - acc: 0.7697 - val_loss: 1.7666 - val_acc: 0.5730\n",
      "Epoch 11/60\n",
      "4681/4681 [==============================] - 3s 617us/step - loss: 0.4780 - acc: 0.7797 - val_loss: 2.5192 - val_acc: 0.4782\n",
      "Epoch 12/60\n",
      "4681/4681 [==============================] - 3s 620us/step - loss: 0.4671 - acc: 0.7909 - val_loss: 0.8719 - val_acc: 0.7609\n",
      "Epoch 13/60\n",
      "4681/4681 [==============================] - 3s 614us/step - loss: 0.4433 - acc: 0.7988 - val_loss: 0.9759 - val_acc: 0.8113\n",
      "Epoch 14/60\n",
      "4681/4681 [==============================] - 3s 615us/step - loss: 0.4279 - acc: 0.8105 - val_loss: 0.6693 - val_acc: 0.7694\n",
      "Epoch 15/60\n",
      "4681/4681 [==============================] - 3s 616us/step - loss: 0.4244 - acc: 0.8146 - val_loss: 0.7321 - val_acc: 0.7472\n",
      "Epoch 16/60\n",
      "4681/4681 [==============================] - 3s 625us/step - loss: 0.4064 - acc: 0.8184 - val_loss: 0.6593 - val_acc: 0.7353\n",
      "Epoch 17/60\n",
      "4681/4681 [==============================] - 3s 615us/step - loss: 0.3880 - acc: 0.8319 - val_loss: 1.3244 - val_acc: 0.5662\n",
      "Epoch 18/60\n",
      "4681/4681 [==============================] - 3s 617us/step - loss: 0.3687 - acc: 0.8370 - val_loss: 0.7765 - val_acc: 0.7865\n",
      "Epoch 19/60\n",
      "4681/4681 [==============================] - 3s 619us/step - loss: 0.3696 - acc: 0.8376 - val_loss: 1.9261 - val_acc: 0.8173\n",
      "Epoch 20/60\n",
      "4681/4681 [==============================] - 3s 617us/step - loss: 0.3546 - acc: 0.8464 - val_loss: 2.5684 - val_acc: 0.4065\n",
      "Epoch 21/60\n",
      "4681/4681 [==============================] - 3s 612us/step - loss: 0.3430 - acc: 0.8579 - val_loss: 1.2707 - val_acc: 0.7985\n",
      "Epoch 22/60\n",
      "4681/4681 [==============================] - 3s 617us/step - loss: 0.3405 - acc: 0.8571 - val_loss: 2.4548 - val_acc: 0.8275\n",
      "Epoch 23/60\n",
      "4681/4681 [==============================] - 3s 613us/step - loss: 0.3354 - acc: 0.8584 - val_loss: 1.2231 - val_acc: 0.7626\n",
      "Epoch 24/60\n",
      "4681/4681 [==============================] - 3s 613us/step - loss: 0.3189 - acc: 0.8729 - val_loss: 1.6761 - val_acc: 0.8190\n",
      "Epoch 25/60\n",
      "4681/4681 [==============================] - 3s 617us/step - loss: 0.3176 - acc: 0.8708 - val_loss: 1.9588 - val_acc: 0.6456\n",
      "Epoch 26/60\n",
      "4681/4681 [==============================] - 3s 620us/step - loss: 0.3015 - acc: 0.8816 - val_loss: 2.0208 - val_acc: 0.6524\n",
      "Epoch 27/60\n",
      "4681/4681 [==============================] - 3s 617us/step - loss: 0.2917 - acc: 0.8827 - val_loss: 2.7904 - val_acc: 0.8258\n",
      "Epoch 28/60\n",
      "4681/4681 [==============================] - 3s 621us/step - loss: 0.2905 - acc: 0.8846 - val_loss: 1.6029 - val_acc: 0.8130\n",
      "Epoch 29/60\n",
      "4681/4681 [==============================] - 3s 618us/step - loss: 0.2751 - acc: 0.8943 - val_loss: 1.1957 - val_acc: 0.7156\n",
      "Epoch 30/60\n",
      "4681/4681 [==============================] - 3s 621us/step - loss: 0.2900 - acc: 0.8887 - val_loss: 0.8620 - val_acc: 0.7353\n",
      "Epoch 31/60\n",
      "4681/4681 [==============================] - 3s 621us/step - loss: 0.2647 - acc: 0.9032 - val_loss: 2.0325 - val_acc: 0.6063\n",
      "Epoch 32/60\n",
      "4681/4681 [==============================] - 3s 624us/step - loss: 0.2658 - acc: 0.9013 - val_loss: 1.8034 - val_acc: 0.6319\n",
      "Epoch 33/60\n",
      "4681/4681 [==============================] - 3s 620us/step - loss: 0.2451 - acc: 0.9049 - val_loss: 1.8506 - val_acc: 0.7498\n",
      "Epoch 34/60\n",
      "4681/4681 [==============================] - 3s 624us/step - loss: 0.2818 - acc: 0.9015 - val_loss: 2.3121 - val_acc: 0.8292\n",
      "Epoch 35/60\n",
      "4681/4681 [==============================] - 3s 621us/step - loss: 0.2617 - acc: 0.9066 - val_loss: 2.4192 - val_acc: 0.7395\n",
      "Epoch 36/60\n",
      "4681/4681 [==============================] - 3s 626us/step - loss: 0.2405 - acc: 0.9143 - val_loss: 2.3633 - val_acc: 0.8155\n",
      "Epoch 37/60\n",
      "4681/4681 [==============================] - 3s 623us/step - loss: 0.2309 - acc: 0.9171 - val_loss: 0.9941 - val_acc: 0.8019\n",
      "Epoch 38/60\n",
      "4681/4681 [==============================] - 3s 622us/step - loss: 0.2231 - acc: 0.9173 - val_loss: 1.9011 - val_acc: 0.8224\n",
      "Epoch 39/60\n",
      "4681/4681 [==============================] - 3s 619us/step - loss: 0.2176 - acc: 0.9237 - val_loss: 2.0212 - val_acc: 0.6166\n",
      "Epoch 40/60\n",
      "4681/4681 [==============================] - 3s 644us/step - loss: 0.2307 - acc: 0.9186 - val_loss: 2.0932 - val_acc: 0.8010\n",
      "Epoch 41/60\n",
      "4681/4681 [==============================] - 3s 638us/step - loss: 0.2276 - acc: 0.9231 - val_loss: 2.2037 - val_acc: 0.8241\n",
      "Epoch 42/60\n",
      "4681/4681 [==============================] - 3s 641us/step - loss: 0.2044 - acc: 0.9321 - val_loss: 2.2200 - val_acc: 0.7353\n",
      "Epoch 43/60\n",
      "4681/4681 [==============================] - 3s 632us/step - loss: 0.2053 - acc: 0.9297 - val_loss: 2.9001 - val_acc: 0.6447\n",
      "Epoch 44/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4681/4681 [==============================] - 3s 626us/step - loss: 0.1974 - acc: 0.9346 - val_loss: 2.5968 - val_acc: 0.5457\n",
      "Epoch 45/60\n",
      "4681/4681 [==============================] - 3s 626us/step - loss: 0.1890 - acc: 0.9383 - val_loss: 2.0615 - val_acc: 0.8147\n",
      "Epoch 46/60\n",
      "4681/4681 [==============================] - 3s 627us/step - loss: 0.2009 - acc: 0.9331 - val_loss: 2.2089 - val_acc: 0.6003\n",
      "Epoch 47/60\n",
      "4681/4681 [==============================] - 3s 627us/step - loss: 0.1973 - acc: 0.9370 - val_loss: 1.1850 - val_acc: 0.7942\n",
      "Epoch 48/60\n",
      "4681/4681 [==============================] - 3s 626us/step - loss: 0.1806 - acc: 0.9387 - val_loss: 1.9477 - val_acc: 0.8138\n",
      "Epoch 49/60\n",
      "4681/4681 [==============================] - 3s 624us/step - loss: 0.1886 - acc: 0.9359 - val_loss: 1.3280 - val_acc: 0.8147\n",
      "Epoch 50/60\n",
      "4681/4681 [==============================] - 3s 628us/step - loss: 0.1845 - acc: 0.9417 - val_loss: 1.1894 - val_acc: 0.8010\n",
      "Epoch 51/60\n",
      "4681/4681 [==============================] - 3s 627us/step - loss: 0.1734 - acc: 0.9430 - val_loss: 1.5611 - val_acc: 0.7652\n",
      "Epoch 52/60\n",
      "4681/4681 [==============================] - 3s 630us/step - loss: 0.1817 - acc: 0.9430 - val_loss: 1.2904 - val_acc: 0.7412\n",
      "Epoch 53/60\n",
      "4681/4681 [==============================] - 3s 627us/step - loss: 0.1672 - acc: 0.9481 - val_loss: 1.9872 - val_acc: 0.7874\n",
      "Epoch 54/60\n",
      "4681/4681 [==============================] - 3s 626us/step - loss: 0.1637 - acc: 0.9485 - val_loss: 1.8056 - val_acc: 0.6379\n",
      "Epoch 55/60\n",
      "4681/4681 [==============================] - 3s 625us/step - loss: 0.1657 - acc: 0.9494 - val_loss: 1.7617 - val_acc: 0.6635\n",
      "Epoch 56/60\n",
      "4681/4681 [==============================] - 3s 628us/step - loss: 0.1658 - acc: 0.9502 - val_loss: 1.7636 - val_acc: 0.8147\n",
      "Epoch 57/60\n",
      "4681/4681 [==============================] - 3s 629us/step - loss: 0.1751 - acc: 0.9466 - val_loss: 1.4948 - val_acc: 0.8079\n",
      "Epoch 58/60\n",
      "4681/4681 [==============================] - 3s 625us/step - loss: 0.1591 - acc: 0.9554 - val_loss: 1.7042 - val_acc: 0.7472\n",
      "Epoch 59/60\n",
      "4681/4681 [==============================] - 3s 628us/step - loss: 0.1568 - acc: 0.9517 - val_loss: 1.7950 - val_acc: 0.7822\n",
      "Epoch 60/60\n",
      "4681/4681 [==============================] - 3s 640us/step - loss: 0.1484 - acc: 0.9601 - val_loss: 1.8311 - val_acc: 0.8036\n",
      "Training advancement:  0 %\n",
      "SavingPrivateRyan\n",
      "Train on 7787 samples, validate on 1947 samples\n",
      "Epoch 1/60\n",
      "7787/7787 [==============================] - 5s 624us/step - loss: 0.7705 - acc: 0.5457 - val_loss: 0.7903 - val_acc: 0.5496\n",
      "Epoch 2/60\n",
      "7787/7787 [==============================] - 5s 613us/step - loss: 0.7035 - acc: 0.5767 - val_loss: 0.8127 - val_acc: 0.4787\n",
      "Epoch 3/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.6849 - acc: 0.6002 - val_loss: 0.8066 - val_acc: 0.5984\n",
      "Epoch 4/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.6711 - acc: 0.6119 - val_loss: 1.1562 - val_acc: 0.6133\n",
      "Epoch 5/60\n",
      "7787/7787 [==============================] - 5s 613us/step - loss: 0.6636 - acc: 0.6198 - val_loss: 4.8471 - val_acc: 0.2974\n",
      "Epoch 6/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.6555 - acc: 0.6233 - val_loss: 0.9215 - val_acc: 0.6446\n",
      "Epoch 7/60\n",
      "7787/7787 [==============================] - 5s 616us/step - loss: 0.6463 - acc: 0.6345 - val_loss: 5.6577 - val_acc: 0.3744\n",
      "Epoch 8/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.6516 - acc: 0.6322 - val_loss: 0.8452 - val_acc: 0.3826\n",
      "Epoch 9/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.6386 - acc: 0.6422 - val_loss: 0.9900 - val_acc: 0.5665\n",
      "Epoch 10/60\n",
      "7787/7787 [==============================] - 5s 618us/step - loss: 0.6357 - acc: 0.6430 - val_loss: 3.4358 - val_acc: 0.3780\n",
      "Epoch 11/60\n",
      "7787/7787 [==============================] - 5s 613us/step - loss: 0.6280 - acc: 0.6508 - val_loss: 1.0377 - val_acc: 0.4777\n",
      "Epoch 12/60\n",
      "7787/7787 [==============================] - 5s 616us/step - loss: 0.6248 - acc: 0.6498 - val_loss: 2.4587 - val_acc: 0.4397\n",
      "Epoch 13/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.6266 - acc: 0.6516 - val_loss: 10.1963 - val_acc: 0.3677\n",
      "Epoch 14/60\n",
      "7787/7787 [==============================] - 5s 613us/step - loss: 0.6147 - acc: 0.6674 - val_loss: 2.1902 - val_acc: 0.5044\n",
      "Epoch 15/60\n",
      "7787/7787 [==============================] - 5s 611us/step - loss: 0.6055 - acc: 0.6737 - val_loss: 2.9488 - val_acc: 0.4828\n",
      "Epoch 16/60\n",
      "7787/7787 [==============================] - 5s 616us/step - loss: 0.6091 - acc: 0.6665 - val_loss: 0.9045 - val_acc: 0.5383\n",
      "Epoch 17/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.6107 - acc: 0.6648 - val_loss: 4.8439 - val_acc: 0.3898\n",
      "Epoch 18/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.5982 - acc: 0.6768 - val_loss: 1.2576 - val_acc: 0.5342\n",
      "Epoch 19/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.5917 - acc: 0.6806 - val_loss: 1.9482 - val_acc: 0.3780\n",
      "Epoch 20/60\n",
      "7787/7787 [==============================] - 5s 613us/step - loss: 0.5871 - acc: 0.6806 - val_loss: 0.8204 - val_acc: 0.5788\n",
      "Epoch 21/60\n",
      "7787/7787 [==============================] - 5s 613us/step - loss: 0.5786 - acc: 0.6882 - val_loss: 9.2516 - val_acc: 0.3780\n",
      "Epoch 22/60\n",
      "7787/7787 [==============================] - 5s 613us/step - loss: 0.5680 - acc: 0.7013 - val_loss: 1.3948 - val_acc: 0.4823\n",
      "Epoch 23/60\n",
      "7787/7787 [==============================] - 5s 621us/step - loss: 0.5622 - acc: 0.7005 - val_loss: 6.6248 - val_acc: 0.3801\n",
      "Epoch 24/60\n",
      "7787/7787 [==============================] - 5s 616us/step - loss: 0.5544 - acc: 0.7090 - val_loss: 1.8736 - val_acc: 0.5316\n",
      "Epoch 25/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.5460 - acc: 0.7141 - val_loss: 1.1144 - val_acc: 0.6225\n",
      "Epoch 26/60\n",
      "7787/7787 [==============================] - 5s 613us/step - loss: 0.5386 - acc: 0.7153 - val_loss: 3.8099 - val_acc: 0.4535\n",
      "Epoch 27/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.5347 - acc: 0.7194 - val_loss: 1.8518 - val_acc: 0.6076\n",
      "Epoch 28/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.5247 - acc: 0.7230 - val_loss: 1.1605 - val_acc: 0.5342\n",
      "Epoch 29/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.5130 - acc: 0.7340 - val_loss: 1.3863 - val_acc: 0.6230\n",
      "Epoch 30/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.5215 - acc: 0.7310 - val_loss: 3.4520 - val_acc: 0.4920\n",
      "Epoch 31/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.5012 - acc: 0.7437 - val_loss: 2.1800 - val_acc: 0.5424\n",
      "Epoch 32/60\n",
      "7787/7787 [==============================] - 5s 612us/step - loss: 0.5034 - acc: 0.7461 - val_loss: 9.2994 - val_acc: 0.3708\n",
      "Epoch 33/60\n",
      "7787/7787 [==============================] - 5s 617us/step - loss: 0.5007 - acc: 0.7437 - val_loss: 5.9331 - val_acc: 0.4294\n",
      "Epoch 34/60\n",
      "7787/7787 [==============================] - 5s 624us/step - loss: 0.4864 - acc: 0.7575 - val_loss: 1.7088 - val_acc: 0.4535\n",
      "Epoch 35/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.4840 - acc: 0.7588 - val_loss: 1.6180 - val_acc: 0.5686\n",
      "Epoch 36/60\n",
      "7787/7787 [==============================] - 5s 617us/step - loss: 0.4704 - acc: 0.7681 - val_loss: 1.1561 - val_acc: 0.5455\n",
      "Epoch 37/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.4661 - acc: 0.7688 - val_loss: 6.8631 - val_acc: 0.4304\n",
      "Epoch 38/60\n",
      "7787/7787 [==============================] - 5s 613us/step - loss: 0.4674 - acc: 0.7699 - val_loss: 1.9263 - val_acc: 0.5958\n",
      "Epoch 39/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.4508 - acc: 0.7792 - val_loss: 1.7651 - val_acc: 0.5532\n",
      "Epoch 40/60\n",
      "7787/7787 [==============================] - 5s 616us/step - loss: 0.4496 - acc: 0.7828 - val_loss: 7.6277 - val_acc: 0.4145\n",
      "Epoch 41/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.4397 - acc: 0.7850 - val_loss: 1.5265 - val_acc: 0.5254\n",
      "Epoch 42/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.4319 - acc: 0.7923 - val_loss: 9.5924 - val_acc: 0.3796\n",
      "Epoch 43/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7787/7787 [==============================] - 5s 612us/step - loss: 0.4325 - acc: 0.7891 - val_loss: 2.5744 - val_acc: 0.5860\n",
      "Epoch 44/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.4309 - acc: 0.7916 - val_loss: 3.0536 - val_acc: 0.6055\n",
      "Epoch 45/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.4272 - acc: 0.7944 - val_loss: 2.8059 - val_acc: 0.3534\n",
      "Epoch 46/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.4234 - acc: 0.7979 - val_loss: 2.3059 - val_acc: 0.4376\n",
      "Epoch 47/60\n",
      "7787/7787 [==============================] - 5s 616us/step - loss: 0.4079 - acc: 0.8078 - val_loss: 1.9796 - val_acc: 0.5244\n",
      "Epoch 48/60\n",
      "7787/7787 [==============================] - 5s 618us/step - loss: 0.3989 - acc: 0.8105 - val_loss: 3.3986 - val_acc: 0.5259\n",
      "Epoch 49/60\n",
      "7787/7787 [==============================] - 5s 620us/step - loss: 0.4006 - acc: 0.8105 - val_loss: 7.1625 - val_acc: 0.4525\n",
      "Epoch 50/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.3953 - acc: 0.8161 - val_loss: 2.8080 - val_acc: 0.5136\n",
      "Epoch 51/60\n",
      "7787/7787 [==============================] - 5s 612us/step - loss: 0.3913 - acc: 0.8184 - val_loss: 3.0655 - val_acc: 0.4859\n",
      "Epoch 52/60\n",
      "7787/7787 [==============================] - 5s 616us/step - loss: 0.3902 - acc: 0.8138 - val_loss: 8.7321 - val_acc: 0.3842\n",
      "Epoch 53/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.3890 - acc: 0.8152 - val_loss: 3.3167 - val_acc: 0.5660\n",
      "Epoch 54/60\n",
      "7787/7787 [==============================] - 5s 612us/step - loss: 0.3788 - acc: 0.8203 - val_loss: 2.6812 - val_acc: 0.4972\n",
      "Epoch 55/60\n",
      "7787/7787 [==============================] - 5s 612us/step - loss: 0.3830 - acc: 0.8214 - val_loss: 2.1517 - val_acc: 0.4448\n",
      "Epoch 56/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.3756 - acc: 0.8304 - val_loss: 4.0440 - val_acc: 0.6040\n",
      "Epoch 57/60\n",
      "7787/7787 [==============================] - 5s 615us/step - loss: 0.3844 - acc: 0.8148 - val_loss: 3.4323 - val_acc: 0.6148\n",
      "Epoch 58/60\n",
      "7787/7787 [==============================] - 5s 616us/step - loss: 0.3677 - acc: 0.8322 - val_loss: 1.5809 - val_acc: 0.6518\n",
      "Epoch 59/60\n",
      "7787/7787 [==============================] - 5s 614us/step - loss: 0.3714 - acc: 0.8257 - val_loss: 9.7266 - val_acc: 0.3729\n",
      "Epoch 60/60\n",
      "7787/7787 [==============================] - 5s 617us/step - loss: 0.3544 - acc: 0.8331 - val_loss: 1.9327 - val_acc: 0.5167\n",
      "Training advancement:  0 %\n",
      "TheBourneIdentity\n",
      "Train on 5447 samples, validate on 1362 samples\n",
      "Epoch 1/25\n",
      "5447/5447 [==============================] - 3s 639us/step - loss: 0.6441 - acc: 0.7432 - val_loss: 0.4024 - val_acc: 0.9258\n",
      "Epoch 2/25\n",
      "5447/5447 [==============================] - 3s 621us/step - loss: 0.5779 - acc: 0.7549 - val_loss: 0.3540 - val_acc: 0.9332\n",
      "Epoch 3/25\n",
      "5447/5447 [==============================] - 3s 615us/step - loss: 0.5723 - acc: 0.7549 - val_loss: 0.4464 - val_acc: 0.9170\n",
      "Epoch 4/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.5670 - acc: 0.7560 - val_loss: 0.5751 - val_acc: 0.7812\n",
      "Epoch 5/25\n",
      "5447/5447 [==============================] - 3s 618us/step - loss: 0.5598 - acc: 0.7571 - val_loss: 0.3764 - val_acc: 0.8979\n",
      "Epoch 6/25\n",
      "5447/5447 [==============================] - 3s 612us/step - loss: 0.5498 - acc: 0.7612 - val_loss: 0.6277 - val_acc: 0.8142\n",
      "Epoch 7/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.5441 - acc: 0.7621 - val_loss: 0.6208 - val_acc: 0.6652\n",
      "Epoch 8/25\n",
      "5447/5447 [==============================] - 3s 616us/step - loss: 0.5345 - acc: 0.7635 - val_loss: 0.3211 - val_acc: 0.9310\n",
      "Epoch 9/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.5318 - acc: 0.7635 - val_loss: 0.3436 - val_acc: 0.9339\n",
      "Epoch 10/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.5257 - acc: 0.7687 - val_loss: 0.4114 - val_acc: 0.9295\n",
      "Epoch 11/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.5231 - acc: 0.7718 - val_loss: 0.6176 - val_acc: 0.7401\n",
      "Epoch 12/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.5135 - acc: 0.7729 - val_loss: 0.3464 - val_acc: 0.9251\n",
      "Epoch 13/25\n",
      "5447/5447 [==============================] - 3s 614us/step - loss: 0.5135 - acc: 0.7718 - val_loss: 0.4767 - val_acc: 0.9207\n",
      "Epoch 14/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.5025 - acc: 0.7751 - val_loss: 0.5147 - val_acc: 0.9280\n",
      "Epoch 15/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.4981 - acc: 0.7782 - val_loss: 0.3776 - val_acc: 0.9104\n",
      "Epoch 16/25\n",
      "5447/5447 [==============================] - 3s 613us/step - loss: 0.4886 - acc: 0.7830 - val_loss: 0.4602 - val_acc: 0.9332\n",
      "Epoch 17/25\n",
      "5447/5447 [==============================] - 3s 611us/step - loss: 0.4875 - acc: 0.7856 - val_loss: 0.6112 - val_acc: 0.8260\n",
      "Epoch 18/25\n",
      "5447/5447 [==============================] - 3s 619us/step - loss: 0.4780 - acc: 0.7892 - val_loss: 0.5101 - val_acc: 0.9295\n",
      "Epoch 19/25\n",
      "5447/5447 [==============================] - 3s 619us/step - loss: 0.4772 - acc: 0.7869 - val_loss: 0.5035 - val_acc: 0.9273\n",
      "Epoch 20/25\n",
      "5447/5447 [==============================] - 3s 622us/step - loss: 0.4711 - acc: 0.7909 - val_loss: 0.3428 - val_acc: 0.9302\n",
      "Epoch 21/25\n",
      "5447/5447 [==============================] - 3s 613us/step - loss: 0.4648 - acc: 0.7918 - val_loss: 0.8468 - val_acc: 0.7276\n",
      "Epoch 22/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.4572 - acc: 0.7982 - val_loss: 0.5227 - val_acc: 0.8634\n",
      "Epoch 23/25\n",
      "5447/5447 [==============================] - 3s 617us/step - loss: 0.4602 - acc: 0.7964 - val_loss: 0.4694 - val_acc: 0.8686\n",
      "Epoch 24/25\n",
      "5447/5447 [==============================] - 3s 615us/step - loss: 0.4437 - acc: 0.8019 - val_loss: 0.5742 - val_acc: 0.8943\n",
      "Epoch 25/25\n",
      "5447/5447 [==============================] - 3s 614us/step - loss: 0.4404 - acc: 0.8041 - val_loss: 1.9697 - val_acc: 0.4523\n",
      "Training advancement:  0 %\n",
      "Leon\n",
      "Train on 5075 samples, validate on 1269 samples\n",
      "Epoch 1/25\n",
      "5075/5075 [==============================] - 3s 617us/step - loss: 0.5800 - acc: 0.7588 - val_loss: 0.3815 - val_acc: 0.9102\n",
      "Epoch 2/25\n",
      "5075/5075 [==============================] - 3s 617us/step - loss: 0.5567 - acc: 0.7677 - val_loss: 0.4386 - val_acc: 0.8716\n",
      "Epoch 3/25\n",
      "5075/5075 [==============================] - 3s 615us/step - loss: 0.5494 - acc: 0.7677 - val_loss: 0.4038 - val_acc: 0.9117\n",
      "Epoch 4/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.5462 - acc: 0.7681 - val_loss: 1.4582 - val_acc: 0.6154\n",
      "Epoch 5/25\n",
      "5075/5075 [==============================] - 3s 613us/step - loss: 0.5393 - acc: 0.7679 - val_loss: 0.6395 - val_acc: 0.7738\n",
      "Epoch 6/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.5368 - acc: 0.7683 - val_loss: 1.0411 - val_acc: 0.6422\n",
      "Epoch 7/25\n",
      "5075/5075 [==============================] - 3s 615us/step - loss: 0.5359 - acc: 0.7693 - val_loss: 0.4366 - val_acc: 0.8968\n",
      "Epoch 8/25\n",
      "5075/5075 [==============================] - 3s 616us/step - loss: 0.5314 - acc: 0.7691 - val_loss: 1.0095 - val_acc: 0.7470\n",
      "Epoch 9/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.5253 - acc: 0.7685 - val_loss: 0.5466 - val_acc: 0.8448\n",
      "Epoch 10/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.5258 - acc: 0.7689 - val_loss: 0.4982 - val_acc: 0.9023\n",
      "Epoch 11/25\n",
      "5075/5075 [==============================] - 3s 617us/step - loss: 0.5198 - acc: 0.7704 - val_loss: 0.8341 - val_acc: 0.7967\n",
      "Epoch 12/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.5171 - acc: 0.7699 - val_loss: 0.5268 - val_acc: 0.8873\n",
      "Epoch 13/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.5138 - acc: 0.7710 - val_loss: 0.4817 - val_acc: 0.8952\n",
      "Epoch 14/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.5101 - acc: 0.7708 - val_loss: 0.6661 - val_acc: 0.9007\n",
      "Epoch 15/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.5055 - acc: 0.7710 - val_loss: 0.5636 - val_acc: 0.8006\n",
      "Epoch 16/25\n",
      "5075/5075 [==============================] - 3s 616us/step - loss: 0.5033 - acc: 0.7732 - val_loss: 0.4967 - val_acc: 0.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.5023 - acc: 0.7738 - val_loss: 0.5095 - val_acc: 0.8842\n",
      "Epoch 18/25\n",
      "5075/5075 [==============================] - 3s 616us/step - loss: 0.4985 - acc: 0.7762 - val_loss: 0.6179 - val_acc: 0.9110\n",
      "Epoch 19/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.4922 - acc: 0.7766 - val_loss: 0.4816 - val_acc: 0.9054\n",
      "Epoch 20/25\n",
      "5075/5075 [==============================] - 3s 614us/step - loss: 0.4928 - acc: 0.7762 - val_loss: 0.7896 - val_acc: 0.7920\n",
      "Epoch 21/25\n",
      "5075/5075 [==============================] - 3s 612us/step - loss: 0.4805 - acc: 0.7825 - val_loss: 4.9084 - val_acc: 0.2790\n",
      "Epoch 22/25\n",
      "5075/5075 [==============================] - 3s 616us/step - loss: 0.4759 - acc: 0.7813 - val_loss: 0.7623 - val_acc: 0.8645\n",
      "Epoch 23/25\n",
      "5075/5075 [==============================] - 3s 613us/step - loss: 0.4740 - acc: 0.7842 - val_loss: 0.6050 - val_acc: 0.8708\n",
      "Epoch 24/25\n",
      "5075/5075 [==============================] - 3s 615us/step - loss: 0.4778 - acc: 0.7844 - val_loss: 4.9760 - val_acc: 0.3176\n",
      "Epoch 25/25\n",
      "5075/5075 [==============================] - 3s 617us/step - loss: 0.4623 - acc: 0.7872 - val_loss: 0.5555 - val_acc: 0.9078\n",
      "Training advancement:  0 %\n",
      "MidnightExpress\n",
      "Train on 5564 samples, validate on 1392 samples\n",
      "Epoch 1/60\n",
      "5564/5564 [==============================] - 3s 617us/step - loss: 0.7129 - acc: 0.5744 - val_loss: 0.7164 - val_acc: 0.5733\n",
      "Epoch 2/60\n",
      "5564/5564 [==============================] - 3s 616us/step - loss: 0.6857 - acc: 0.5872 - val_loss: 0.7189 - val_acc: 0.5754\n",
      "Epoch 3/60\n",
      "5564/5564 [==============================] - 3s 612us/step - loss: 0.6749 - acc: 0.5881 - val_loss: 1.1966 - val_acc: 0.5718\n",
      "Epoch 4/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.6729 - acc: 0.5988 - val_loss: 0.6943 - val_acc: 0.5891\n",
      "Epoch 5/60\n",
      "5564/5564 [==============================] - 3s 617us/step - loss: 0.6601 - acc: 0.6037 - val_loss: 0.9842 - val_acc: 0.5682\n",
      "Epoch 6/60\n",
      "5564/5564 [==============================] - 3s 618us/step - loss: 0.6548 - acc: 0.6148 - val_loss: 0.7355 - val_acc: 0.5754\n",
      "Epoch 7/60\n",
      "5564/5564 [==============================] - 3s 617us/step - loss: 0.6451 - acc: 0.6281 - val_loss: 0.8910 - val_acc: 0.5625\n",
      "Epoch 8/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.6409 - acc: 0.6337 - val_loss: 1.5019 - val_acc: 0.5057\n",
      "Epoch 9/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.6387 - acc: 0.6371 - val_loss: 0.9283 - val_acc: 0.5740\n",
      "Epoch 10/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.6320 - acc: 0.6416 - val_loss: 3.4166 - val_acc: 0.5474\n",
      "Epoch 11/60\n",
      "5564/5564 [==============================] - 3s 612us/step - loss: 0.6216 - acc: 0.6436 - val_loss: 2.7330 - val_acc: 0.5632\n",
      "Epoch 12/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.6186 - acc: 0.6432 - val_loss: 0.7944 - val_acc: 0.5122\n",
      "Epoch 13/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.6131 - acc: 0.6488 - val_loss: 6.8576 - val_acc: 0.5733\n",
      "Epoch 14/60\n",
      "5564/5564 [==============================] - 3s 616us/step - loss: 0.6086 - acc: 0.6531 - val_loss: 1.3583 - val_acc: 0.4246\n",
      "Epoch 15/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.6046 - acc: 0.6637 - val_loss: 0.9152 - val_acc: 0.5697\n",
      "Epoch 16/60\n",
      "5564/5564 [==============================] - 3s 611us/step - loss: 0.5997 - acc: 0.6733 - val_loss: 1.1752 - val_acc: 0.6056\n",
      "Epoch 17/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.5944 - acc: 0.6804 - val_loss: 0.8786 - val_acc: 0.5711\n",
      "Epoch 18/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.5882 - acc: 0.6831 - val_loss: 0.8699 - val_acc: 0.5388\n",
      "Epoch 19/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.5777 - acc: 0.6885 - val_loss: 1.3380 - val_acc: 0.4842\n",
      "Epoch 20/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.5761 - acc: 0.6928 - val_loss: 0.9706 - val_acc: 0.5359\n",
      "Epoch 21/60\n",
      "5564/5564 [==============================] - 3s 616us/step - loss: 0.5723 - acc: 0.6932 - val_loss: 3.5169 - val_acc: 0.5754\n",
      "Epoch 22/60\n",
      "5564/5564 [==============================] - 3s 617us/step - loss: 0.5648 - acc: 0.7067 - val_loss: 1.8875 - val_acc: 0.5409\n",
      "Epoch 23/60\n",
      "5564/5564 [==============================] - 3s 611us/step - loss: 0.5630 - acc: 0.6990 - val_loss: 1.4078 - val_acc: 0.5517\n",
      "Epoch 24/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.5527 - acc: 0.7085 - val_loss: 1.2053 - val_acc: 0.5704\n",
      "Epoch 25/60\n",
      "5564/5564 [==============================] - 3s 611us/step - loss: 0.5482 - acc: 0.7088 - val_loss: 4.0799 - val_acc: 0.5797\n",
      "Epoch 26/60\n",
      "5564/5564 [==============================] - 3s 616us/step - loss: 0.5407 - acc: 0.7092 - val_loss: 1.5949 - val_acc: 0.4806\n",
      "Epoch 27/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.5328 - acc: 0.7256 - val_loss: 2.2832 - val_acc: 0.5948\n",
      "Epoch 28/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.5332 - acc: 0.7223 - val_loss: 5.6453 - val_acc: 0.4353\n",
      "Epoch 29/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.5319 - acc: 0.7266 - val_loss: 1.6008 - val_acc: 0.5165\n",
      "Epoch 30/60\n",
      "5564/5564 [==============================] - 3s 611us/step - loss: 0.5215 - acc: 0.7304 - val_loss: 1.1858 - val_acc: 0.5065\n",
      "Epoch 31/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.5116 - acc: 0.7457 - val_loss: 1.0335 - val_acc: 0.5999\n",
      "Epoch 32/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.5203 - acc: 0.7313 - val_loss: 2.4252 - val_acc: 0.5438\n",
      "Epoch 33/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.5102 - acc: 0.7347 - val_loss: 3.0734 - val_acc: 0.5323\n",
      "Epoch 34/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.5019 - acc: 0.7466 - val_loss: 1.2519 - val_acc: 0.5000\n",
      "Epoch 35/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.4976 - acc: 0.7482 - val_loss: 4.9028 - val_acc: 0.5632\n",
      "Epoch 36/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.4954 - acc: 0.7531 - val_loss: 1.1597 - val_acc: 0.5596\n",
      "Epoch 37/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.4859 - acc: 0.7583 - val_loss: 1.5773 - val_acc: 0.5668\n",
      "Epoch 38/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.4871 - acc: 0.7575 - val_loss: 1.2860 - val_acc: 0.5453\n",
      "Epoch 39/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.4714 - acc: 0.7601 - val_loss: 1.2918 - val_acc: 0.5898\n",
      "Epoch 40/60\n",
      "5564/5564 [==============================] - 3s 617us/step - loss: 0.4720 - acc: 0.7638 - val_loss: 2.1790 - val_acc: 0.5761\n",
      "Epoch 41/60\n",
      "5564/5564 [==============================] - 3s 619us/step - loss: 0.4686 - acc: 0.7703 - val_loss: 1.3839 - val_acc: 0.5855\n",
      "Epoch 42/60\n",
      "5564/5564 [==============================] - 3s 616us/step - loss: 0.4609 - acc: 0.7739 - val_loss: 3.2063 - val_acc: 0.5826\n",
      "Epoch 43/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.4620 - acc: 0.7707 - val_loss: 4.0800 - val_acc: 0.5805\n",
      "Epoch 44/60\n",
      "5564/5564 [==============================] - 3s 612us/step - loss: 0.4559 - acc: 0.7739 - val_loss: 1.4228 - val_acc: 0.6214\n",
      "Epoch 45/60\n",
      "5564/5564 [==============================] - 3s 611us/step - loss: 0.4576 - acc: 0.7728 - val_loss: 1.3639 - val_acc: 0.5754\n",
      "Epoch 46/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.4420 - acc: 0.7809 - val_loss: 1.4727 - val_acc: 0.4691\n",
      "Epoch 47/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.4356 - acc: 0.7863 - val_loss: 3.2648 - val_acc: 0.4080\n",
      "Epoch 48/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.4338 - acc: 0.7921 - val_loss: 1.2691 - val_acc: 0.5833\n",
      "Epoch 49/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.4288 - acc: 0.7904 - val_loss: 1.5827 - val_acc: 0.5920\n",
      "Epoch 50/60\n",
      "5564/5564 [==============================] - 3s 616us/step - loss: 0.4242 - acc: 0.7895 - val_loss: 2.0643 - val_acc: 0.5115\n",
      "Epoch 51/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.4251 - acc: 0.7933 - val_loss: 2.2276 - val_acc: 0.5517\n",
      "Epoch 52/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.4150 - acc: 0.8039 - val_loss: 4.6579 - val_acc: 0.5575\n",
      "Epoch 53/60\n",
      "5564/5564 [==============================] - 3s 613us/step - loss: 0.4098 - acc: 0.8034 - val_loss: 1.3522 - val_acc: 0.5726\n",
      "Epoch 54/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.4115 - acc: 0.8027 - val_loss: 3.3871 - val_acc: 0.5704\n",
      "Epoch 55/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.4038 - acc: 0.8066 - val_loss: 1.9800 - val_acc: 0.5855\n",
      "Epoch 56/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.4218 - acc: 0.8027 - val_loss: 6.4862 - val_acc: 0.5747\n",
      "Epoch 57/60\n",
      "5564/5564 [==============================] - 3s 616us/step - loss: 0.3992 - acc: 0.8088 - val_loss: 3.9897 - val_acc: 0.5144\n",
      "Epoch 58/60\n",
      "5564/5564 [==============================] - 3s 612us/step - loss: 0.4076 - acc: 0.8068 - val_loss: 1.6219 - val_acc: 0.5453\n",
      "Epoch 59/60\n",
      "5564/5564 [==============================] - 3s 615us/step - loss: 0.3950 - acc: 0.8084 - val_loss: 2.1594 - val_acc: 0.5697\n",
      "Epoch 60/60\n",
      "5564/5564 [==============================] - 3s 614us/step - loss: 0.3884 - acc: 0.8197 - val_loss: 1.5540 - val_acc: 0.5244\n",
      "Training advancement:  0 %\n",
      "Armageddon\n",
      "Train on 6793 samples, validate on 1699 samples\n",
      "Epoch 1/60\n",
      "6793/6793 [==============================] - 4s 618us/step - loss: 0.7165 - acc: 0.6087 - val_loss: 0.7132 - val_acc: 0.5262\n",
      "Epoch 2/60\n",
      "6793/6793 [==============================] - 4s 618us/step - loss: 0.6658 - acc: 0.6439 - val_loss: 0.6752 - val_acc: 0.5533\n",
      "Epoch 3/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.6520 - acc: 0.6499 - val_loss: 0.6072 - val_acc: 0.7222\n",
      "Epoch 4/60\n",
      "6793/6793 [==============================] - 4s 611us/step - loss: 0.6400 - acc: 0.6633 - val_loss: 0.9024 - val_acc: 0.6115\n",
      "Epoch 5/60\n",
      "6793/6793 [==============================] - 4s 604us/step - loss: 0.6311 - acc: 0.6661 - val_loss: 0.7410 - val_acc: 0.5827\n",
      "Epoch 6/60\n",
      "6793/6793 [==============================] - 4s 613us/step - loss: 0.6231 - acc: 0.6742 - val_loss: 0.8587 - val_acc: 0.5662\n",
      "Epoch 7/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.6155 - acc: 0.6867 - val_loss: 0.5939 - val_acc: 0.7634\n",
      "Epoch 8/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.6082 - acc: 0.6945 - val_loss: 0.6314 - val_acc: 0.7675\n",
      "Epoch 9/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.6001 - acc: 0.7016 - val_loss: 3.4793 - val_acc: 0.2078\n",
      "Epoch 10/60\n",
      "6793/6793 [==============================] - 4s 617us/step - loss: 0.5958 - acc: 0.7066 - val_loss: 1.4988 - val_acc: 0.4273\n",
      "Epoch 11/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.5870 - acc: 0.7128 - val_loss: 1.0950 - val_acc: 0.5079\n",
      "Epoch 12/60\n",
      "6793/6793 [==============================] - 4s 617us/step - loss: 0.5822 - acc: 0.7135 - val_loss: 1.1363 - val_acc: 0.3714\n",
      "Epoch 13/60\n",
      "6793/6793 [==============================] - 4s 619us/step - loss: 0.5777 - acc: 0.7187 - val_loss: 0.6472 - val_acc: 0.7775\n",
      "Epoch 14/60\n",
      "6793/6793 [==============================] - 4s 618us/step - loss: 0.5725 - acc: 0.7203 - val_loss: 0.7886 - val_acc: 0.6616\n",
      "Epoch 15/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.5651 - acc: 0.7216 - val_loss: 1.2775 - val_acc: 0.4891\n",
      "Epoch 16/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.5586 - acc: 0.7310 - val_loss: 2.2880 - val_acc: 0.3579\n",
      "Epoch 17/60\n",
      "6793/6793 [==============================] - 4s 617us/step - loss: 0.5513 - acc: 0.7288 - val_loss: 0.8301 - val_acc: 0.6051\n",
      "Epoch 18/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.5457 - acc: 0.7412 - val_loss: 1.5543 - val_acc: 0.6410\n",
      "Epoch 19/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.5434 - acc: 0.7377 - val_loss: 3.1789 - val_acc: 0.8016\n",
      "Epoch 20/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.5311 - acc: 0.7444 - val_loss: 0.6364 - val_acc: 0.7852\n",
      "Epoch 21/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.5293 - acc: 0.7522 - val_loss: 0.6926 - val_acc: 0.7139\n",
      "Epoch 22/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.5232 - acc: 0.7506 - val_loss: 0.7783 - val_acc: 0.7575\n",
      "Epoch 23/60\n",
      "6793/6793 [==============================] - 4s 613us/step - loss: 0.5168 - acc: 0.7559 - val_loss: 1.2654 - val_acc: 0.5821\n",
      "Epoch 24/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.5130 - acc: 0.7630 - val_loss: 1.0956 - val_acc: 0.5079\n",
      "Epoch 25/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.5069 - acc: 0.7614 - val_loss: 1.7481 - val_acc: 0.3896\n",
      "Epoch 26/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.4957 - acc: 0.7667 - val_loss: 0.9164 - val_acc: 0.6939\n",
      "Epoch 27/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.4885 - acc: 0.7751 - val_loss: 1.2721 - val_acc: 0.5668\n",
      "Epoch 28/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.4942 - acc: 0.7683 - val_loss: 2.0474 - val_acc: 0.3985\n",
      "Epoch 29/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.4831 - acc: 0.7780 - val_loss: 0.8329 - val_acc: 0.7251\n",
      "Epoch 30/60\n",
      "6793/6793 [==============================] - 4s 613us/step - loss: 0.4693 - acc: 0.7898 - val_loss: 2.3642 - val_acc: 0.4067\n",
      "Epoch 31/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.4711 - acc: 0.7868 - val_loss: 0.8993 - val_acc: 0.6574\n",
      "Epoch 32/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.4646 - acc: 0.7917 - val_loss: 0.8732 - val_acc: 0.6998\n",
      "Epoch 33/60\n",
      "6793/6793 [==============================] - 4s 613us/step - loss: 0.4543 - acc: 0.7974 - val_loss: 1.0492 - val_acc: 0.7034\n",
      "Epoch 34/60\n",
      "6793/6793 [==============================] - 4s 612us/step - loss: 0.4521 - acc: 0.7971 - val_loss: 1.1486 - val_acc: 0.6516\n",
      "Epoch 35/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.4559 - acc: 0.7943 - val_loss: 1.2185 - val_acc: 0.7457\n",
      "Epoch 36/60\n",
      "6793/6793 [==============================] - 4s 612us/step - loss: 0.4498 - acc: 0.7983 - val_loss: 1.2347 - val_acc: 0.6392\n",
      "Epoch 37/60\n",
      "6793/6793 [==============================] - 4s 612us/step - loss: 0.4366 - acc: 0.8051 - val_loss: 1.1512 - val_acc: 0.5368\n",
      "Epoch 38/60\n",
      "6793/6793 [==============================] - 4s 612us/step - loss: 0.4343 - acc: 0.8072 - val_loss: 2.0217 - val_acc: 0.4762\n",
      "Epoch 39/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.4263 - acc: 0.8126 - val_loss: 0.8295 - val_acc: 0.6763\n",
      "Epoch 40/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.4270 - acc: 0.8151 - val_loss: 1.2395 - val_acc: 0.6904\n",
      "Epoch 41/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.4237 - acc: 0.8133 - val_loss: 0.8623 - val_acc: 0.6886\n",
      "Epoch 42/60\n",
      "6793/6793 [==============================] - 4s 618us/step - loss: 0.4071 - acc: 0.8214 - val_loss: 1.7061 - val_acc: 0.5927\n",
      "Epoch 43/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.4055 - acc: 0.8194 - val_loss: 1.3818 - val_acc: 0.7546\n",
      "Epoch 44/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.4084 - acc: 0.8206 - val_loss: 1.6684 - val_acc: 0.6192\n",
      "Epoch 45/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.4032 - acc: 0.8214 - val_loss: 1.7622 - val_acc: 0.5974\n",
      "Epoch 46/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.4111 - acc: 0.8276 - val_loss: 1.2613 - val_acc: 0.6398\n",
      "Epoch 47/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.3950 - acc: 0.8266 - val_loss: 7.7570 - val_acc: 0.2672\n",
      "Epoch 48/60\n",
      "6793/6793 [==============================] - 4s 613us/step - loss: 0.3972 - acc: 0.8269 - val_loss: 1.8091 - val_acc: 0.5303\n",
      "Epoch 49/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.3909 - acc: 0.8317 - val_loss: 2.8268 - val_acc: 0.4397\n",
      "Epoch 50/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.3774 - acc: 0.8406 - val_loss: 11.2221 - val_acc: 0.2301\n",
      "Epoch 51/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.3786 - acc: 0.8388 - val_loss: 1.1813 - val_acc: 0.6527\n",
      "Epoch 52/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.3756 - acc: 0.8373 - val_loss: 1.5982 - val_acc: 0.5903\n",
      "Epoch 53/60\n",
      "6793/6793 [==============================] - 4s 617us/step - loss: 0.3758 - acc: 0.8376 - val_loss: 1.2200 - val_acc: 0.7316\n",
      "Epoch 54/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.3719 - acc: 0.8438 - val_loss: 1.0629 - val_acc: 0.6727\n",
      "Epoch 55/60\n",
      "6793/6793 [==============================] - 4s 614us/step - loss: 0.3714 - acc: 0.8473 - val_loss: 1.2449 - val_acc: 0.6869\n",
      "Epoch 56/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.3645 - acc: 0.8470 - val_loss: 8.4213 - val_acc: 0.2295\n",
      "Epoch 57/60\n",
      "6793/6793 [==============================] - 4s 615us/step - loss: 0.3540 - acc: 0.8496 - val_loss: 1.5532 - val_acc: 0.6657\n",
      "Epoch 58/60\n",
      "6793/6793 [==============================] - 4s 616us/step - loss: 0.3575 - acc: 0.8485 - val_loss: 1.6957 - val_acc: 0.6686\n",
      "Epoch 59/60\n",
      "6793/6793 [==============================] - 4s 613us/step - loss: 0.3474 - acc: 0.8544 - val_loss: 2.7898 - val_acc: 0.4261\n",
      "Epoch 60/60\n",
      "6793/6793 [==============================] - 4s 617us/step - loss: 0.3493 - acc: 0.8519 - val_loss: 2.2369 - val_acc: 0.5527\n",
      "Training advancement:  0 %\n",
      "IndependanceDay\n",
      "Train on 7065 samples, validate on 1767 samples\n",
      "Epoch 1/25\n",
      "7065/7065 [==============================] - 4s 626us/step - loss: 0.5092 - acc: 0.8211 - val_loss: 0.3854 - val_acc: 0.8732\n",
      "Epoch 2/25\n",
      "7065/7065 [==============================] - 4s 615us/step - loss: 0.4700 - acc: 0.8272 - val_loss: 0.3910 - val_acc: 0.8744\n",
      "Epoch 3/25\n",
      "7065/7065 [==============================] - 4s 612us/step - loss: 0.4578 - acc: 0.8290 - val_loss: 2.4642 - val_acc: 0.1483\n",
      "Epoch 4/25\n",
      "7065/7065 [==============================] - 4s 613us/step - loss: 0.4496 - acc: 0.8299 - val_loss: 2.0666 - val_acc: 0.2569\n",
      "Epoch 5/25\n",
      "7065/7065 [==============================] - 4s 614us/step - loss: 0.4452 - acc: 0.8309 - val_loss: 0.3698 - val_acc: 0.8806\n",
      "Epoch 6/25\n",
      "7065/7065 [==============================] - 4s 614us/step - loss: 0.4419 - acc: 0.8323 - val_loss: 0.3655 - val_acc: 0.8812\n",
      "Epoch 7/25\n",
      "7065/7065 [==============================] - 4s 612us/step - loss: 0.4399 - acc: 0.8326 - val_loss: 0.3704 - val_acc: 0.8789\n",
      "Epoch 8/25\n",
      "7065/7065 [==============================] - 4s 616us/step - loss: 0.4335 - acc: 0.8301 - val_loss: 0.3786 - val_acc: 0.8789\n",
      "Epoch 9/25\n",
      "7065/7065 [==============================] - 4s 614us/step - loss: 0.4297 - acc: 0.8330 - val_loss: 0.5144 - val_acc: 0.8093\n",
      "Epoch 10/25\n",
      "7065/7065 [==============================] - 4s 618us/step - loss: 0.4292 - acc: 0.8333 - val_loss: 0.3758 - val_acc: 0.8789\n",
      "Epoch 11/25\n",
      "7065/7065 [==============================] - 4s 614us/step - loss: 0.4261 - acc: 0.8333 - val_loss: 0.4199 - val_acc: 0.8789\n",
      "Epoch 12/25\n",
      "7065/7065 [==============================] - 4s 612us/step - loss: 0.4271 - acc: 0.8330 - val_loss: 0.3852 - val_acc: 0.8789\n",
      "Epoch 13/25\n",
      "7065/7065 [==============================] - 4s 612us/step - loss: 0.4215 - acc: 0.8360 - val_loss: 0.3667 - val_acc: 0.8795\n",
      "Epoch 14/25\n",
      "7065/7065 [==============================] - 4s 615us/step - loss: 0.4217 - acc: 0.8347 - val_loss: 0.4003 - val_acc: 0.8795\n",
      "Epoch 15/25\n",
      "7065/7065 [==============================] - 4s 612us/step - loss: 0.4168 - acc: 0.8341 - val_loss: 0.4269 - val_acc: 0.8829\n",
      "Epoch 16/25\n",
      "7065/7065 [==============================] - 4s 610us/step - loss: 0.4202 - acc: 0.8354 - val_loss: 0.3952 - val_acc: 0.8778\n",
      "Epoch 17/25\n",
      "7065/7065 [==============================] - 4s 615us/step - loss: 0.4148 - acc: 0.8343 - val_loss: 0.3918 - val_acc: 0.8789\n",
      "Epoch 18/25\n",
      "7065/7065 [==============================] - 4s 612us/step - loss: 0.4139 - acc: 0.8348 - val_loss: 0.4320 - val_acc: 0.8789\n",
      "Epoch 19/25\n",
      "7065/7065 [==============================] - 4s 614us/step - loss: 0.4100 - acc: 0.8334 - val_loss: 0.4028 - val_acc: 0.8795\n",
      "Epoch 20/25\n",
      "7065/7065 [==============================] - 4s 613us/step - loss: 0.4107 - acc: 0.8350 - val_loss: 0.4007 - val_acc: 0.8846\n",
      "Epoch 21/25\n",
      "7065/7065 [==============================] - 4s 613us/step - loss: 0.4104 - acc: 0.8362 - val_loss: 0.4135 - val_acc: 0.8789\n",
      "Epoch 22/25\n",
      "7065/7065 [==============================] - 4s 615us/step - loss: 0.4107 - acc: 0.8364 - val_loss: 0.4097 - val_acc: 0.8568\n",
      "Epoch 23/25\n",
      "7065/7065 [==============================] - 4s 613us/step - loss: 0.4063 - acc: 0.8334 - val_loss: 0.3708 - val_acc: 0.8800\n",
      "Epoch 24/25\n",
      "7065/7065 [==============================] - 4s 615us/step - loss: 0.4066 - acc: 0.8391 - val_loss: 0.3927 - val_acc: 0.8795\n",
      "Epoch 25/25\n",
      "7065/7065 [==============================] - 4s 617us/step - loss: 0.4010 - acc: 0.8371 - val_loss: 1.2064 - val_acc: 0.8834\n",
      "Training advancement:  0 %\n",
      "DeadPoetsSociety\n",
      "Train on 5927 samples, validate on 1482 samples\n",
      "Epoch 1/25\n",
      "5927/5927 [==============================] - 4s 619us/step - loss: 0.7323 - acc: 0.5139 - val_loss: 0.7010 - val_acc: 0.4885\n",
      "Epoch 2/25\n",
      "5927/5927 [==============================] - 4s 618us/step - loss: 0.6992 - acc: 0.5166 - val_loss: 0.6462 - val_acc: 0.7422\n",
      "Epoch 3/25\n",
      "5927/5927 [==============================] - 4s 617us/step - loss: 0.6923 - acc: 0.5261 - val_loss: 0.6702 - val_acc: 0.5250\n",
      "Epoch 4/25\n",
      "5927/5927 [==============================] - 4s 613us/step - loss: 0.6887 - acc: 0.5289 - val_loss: 0.6095 - val_acc: 0.5594\n",
      "Epoch 5/25\n",
      "5927/5927 [==============================] - 4s 615us/step - loss: 0.6819 - acc: 0.5340 - val_loss: 0.6967 - val_acc: 0.4035\n",
      "Epoch 6/25\n",
      "5927/5927 [==============================] - 4s 616us/step - loss: 0.6809 - acc: 0.5413 - val_loss: 0.7177 - val_acc: 0.3354\n",
      "Epoch 7/25\n",
      "5927/5927 [==============================] - 4s 615us/step - loss: 0.6823 - acc: 0.5380 - val_loss: 0.6395 - val_acc: 0.6842\n",
      "Epoch 8/25\n",
      "5927/5927 [==============================] - 4s 612us/step - loss: 0.6799 - acc: 0.5473 - val_loss: 0.6121 - val_acc: 0.5128\n",
      "Epoch 9/25\n",
      "5927/5927 [==============================] - 4s 615us/step - loss: 0.6761 - acc: 0.5524 - val_loss: 0.6106 - val_acc: 0.4993\n",
      "Epoch 10/25\n",
      "5927/5927 [==============================] - 4s 619us/step - loss: 0.6711 - acc: 0.5580 - val_loss: 0.5393 - val_acc: 0.5769\n",
      "Epoch 11/25\n",
      "5927/5927 [==============================] - 4s 615us/step - loss: 0.6688 - acc: 0.5649 - val_loss: 0.5797 - val_acc: 0.6174\n",
      "Epoch 12/25\n",
      "5927/5927 [==============================] - 4s 616us/step - loss: 0.6672 - acc: 0.5628 - val_loss: 0.4296 - val_acc: 0.8144\n",
      "Epoch 13/25\n",
      "5927/5927 [==============================] - 4s 613us/step - loss: 0.6589 - acc: 0.5779 - val_loss: 4.0989 - val_acc: 0.6984\n",
      "Epoch 14/25\n",
      "5927/5927 [==============================] - 4s 615us/step - loss: 0.6601 - acc: 0.5829 - val_loss: 0.8471 - val_acc: 0.3192\n",
      "Epoch 15/25\n",
      "5927/5927 [==============================] - 4s 617us/step - loss: 0.6578 - acc: 0.5829 - val_loss: 0.7544 - val_acc: 0.3596\n",
      "Epoch 16/25\n",
      "5927/5927 [==============================] - 4s 618us/step - loss: 0.6555 - acc: 0.5871 - val_loss: 0.9513 - val_acc: 0.6943\n",
      "Epoch 17/25\n",
      "5927/5927 [==============================] - 4s 617us/step - loss: 0.6583 - acc: 0.5853 - val_loss: 0.6051 - val_acc: 0.4845\n",
      "Epoch 18/25\n",
      "5927/5927 [==============================] - 4s 616us/step - loss: 0.6481 - acc: 0.5971 - val_loss: 4.7699 - val_acc: 0.6829\n",
      "Epoch 19/25\n",
      "5927/5927 [==============================] - 4s 616us/step - loss: 0.6502 - acc: 0.5983 - val_loss: 1.0501 - val_acc: 0.4730\n",
      "Epoch 20/25\n",
      "5927/5927 [==============================] - 4s 616us/step - loss: 0.6429 - acc: 0.6049 - val_loss: 0.7831 - val_acc: 0.4123\n",
      "Epoch 21/25\n",
      "5927/5927 [==============================] - 4s 614us/step - loss: 0.6409 - acc: 0.6076 - val_loss: 0.7946 - val_acc: 0.4683\n",
      "Epoch 22/25\n",
      "5927/5927 [==============================] - 4s 611us/step - loss: 0.6409 - acc: 0.6037 - val_loss: 0.9721 - val_acc: 0.4791\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5927/5927 [==============================] - 4s 615us/step - loss: 0.6378 - acc: 0.6086 - val_loss: 0.8307 - val_acc: 0.7794\n",
      "Epoch 24/25\n",
      "5927/5927 [==============================] - 4s 614us/step - loss: 0.6284 - acc: 0.6163 - val_loss: 0.9253 - val_acc: 0.4116\n",
      "Epoch 25/25\n",
      "5927/5927 [==============================] - 4s 615us/step - loss: 0.6285 - acc: 0.6189 - val_loss: 0.7749 - val_acc: 0.7375\n",
      "Training advancement:  100 %\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "i = 0\n",
    "for movie in uDataNames:\n",
    "    print(movie)\n",
    "    epVal = 25\n",
    "    if(movie in [\"BillyElliot\", \"MidnightExpress\", \"SavingPrivateRyan\", \"Armageddon\", \"TheWickerMan\", \"TheWizardOfOz\", \"TheSixthSense\", \"Eragon\"]):\n",
    "        epVal = 60\n",
    "    trainDataFile = h5py.File(dataPath + movie +\"_auditory.mat\")\n",
    "    trainTags = pd.read_csv(annotationsPath + movie + \"_screams.txt\", sep = \" \", header = None)\n",
    "\n",
    "    trainData, trainTags = prepareData(np.array(trainDataFile.get(\"MFCC\")), trainTags)\n",
    "    ftrainData, ftrainTags = flattenData(trainData, trainTags)\n",
    "    ftrainData = ftrainData.astype('float32')/3250\n",
    "    \n",
    "    results[movie] = model.fit(ftrainData, ftrainTags, epochs = epVal, validation_split = 0.2)\n",
    "    i += 1\n",
    "    print(\"Training advancement: \", int(float(i)/len(uDataNames)*100), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"modelv4.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"modelv4.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPath = \"./Datasets/VSD_2014_December_official_release/YouTube-gen/features/\"\n",
    "\n",
    "test_names = listdir(testPath)\n",
    "\n",
    "uTestNames = set()\n",
    "\n",
    "for fname in test_names:\n",
    "    uTestNames.add(fname.replace(dName.search(fname).group(), ''))\n",
    "        \n",
    "uTestNames = list(uTestNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YULESOhr7Rg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2538b142240>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testName = uTestNames[rnd.randint(0, len(uTestNames) - 1)]\n",
    "print(testName)\n",
    "testDataFile = h5py.File(testPath + testName +\"_auditory.mat\")\n",
    "testData = np.array(testDataFile.get(\"MFCC\"))\n",
    "result = []\n",
    "\n",
    "i = 0\n",
    "while(len(testData) > i+tWindow):\n",
    "    prepare = testData[i:i+tWindow]\n",
    "    prepare = prepare.astype('float32')/3250\n",
    "    result.append(model.predict(np.expand_dims(testData[i:i+tWindow], axis = 0)))\n",
    "    i += tWindow\n",
    "    \n",
    "if(len(testData)%tWindow != 0):\n",
    "    residue = np.concatenate((testData[i:len(testData)], np.zeros(((tWindow-(len(testData)%tWindow)), 22))), axis = 0)\n",
    "    result.append(model.predict(np.expand_dims(residue, axis = 0))[0])\n",
    "\n",
    "plt.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
